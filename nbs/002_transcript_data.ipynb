{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6795c27b",
   "metadata": {},
   "source": [
    "# Transcript Data  \n",
    "> This module retrieves genomic coordinates and other key information related to transcripts from a GTF file. Using **pyRanges**, it efficiently stores and visualizes transcript features like exons, CDS, and UTRs.  \n",
    "\n",
    "The module also supports tasks like intron coordinate calculation, transcript length measurement, and batch queries. It includes optional sequence retrieval from a reference genome and tools for analyzing alternative splicing events. Caching is used to speed up repeated queries, making it ideal for working with large datasets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efaf95b09bc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad48354c112d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0fe828ba5c3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from functools import lru_cache\n",
    "import pyranges as pr\n",
    "from pyfaidx import Fasta\n",
    "import logging\n",
    "import re\n",
    "from typing import Any, Dict, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TranscriptData:\n",
    "    \"\"\"\n",
    "    A class for managing transcript and gene information from a GTF file using PyRanges.\n",
    "\n",
    "    Existing Features:\n",
    "      - Lookup by transcript ID or gene ID/name\n",
    "      - Support for exons, CDS, UTR queries\n",
    "      - Intron coordinate calculation\n",
    "      - Batch queries\n",
    "      - Transcript length calculation\n",
    "      - Caching/memoization for repeated queries\n",
    "      - Basic logging/error handling\n",
    "\n",
    "    NEW Features:\n",
    "      (1) Nucleotide/protein sequence retrieval for CDS (with optional FASTA)\n",
    "      (2) Alternative splicing analysis with splice junctions, isoform comparisons,\n",
    "          and junction-chain interpretation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gtf_file: str, reference_fasta: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Read the GTF file into a PyRanges object and store it.\n",
    "        Optionally store a path to a reference FASTA for sequence methods.\n",
    "\n",
    "        Args:\n",
    "            gtf_file (str): Path to a GTF/GFF file.\n",
    "            reference_fasta (str, optional): Path to a reference genome FASTA.\n",
    "        \"\"\"\n",
    "        self.gtf_file = gtf_file\n",
    "        self.reference_fasta = reference_fasta  # store for later use\n",
    "        logging.info(f\"Loading GTF from {gtf_file}. This may take a while...\")\n",
    "        try:\n",
    "            self.gr = pr.read_gtf(gtf_file)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading GTF file: {e}\")\n",
    "            raise\n",
    "        logging.info(\"GTF loaded successfully.\")\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_exons(self, transcript_id: str) -> pr.PyRanges:\n",
    "        \"\"\"\n",
    "        Returns a PyRanges of exons for the given transcript.\n",
    "        Results are cached for faster repeat lookups.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to filter on.\n",
    "\n",
    "        Returns:\n",
    "            pr.PyRanges: PyRanges containing exon features for the transcript.\n",
    "        \"\"\"\n",
    "        exons = self.gr[(self.gr.Feature == \"exon\") & (self.gr.transcript_id == transcript_id)]\n",
    "        if len(exons) == 0:\n",
    "            logging.warning(f\"No exons found for transcript {transcript_id}.\")\n",
    "        return exons\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_cds(self, transcript_id: str) -> pr.PyRanges:\n",
    "        \"\"\"\n",
    "        Returns a PyRanges of CDS features for the given transcript.\n",
    "        Results are cached for faster repeat lookups.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to filter on.\n",
    "\n",
    "        Returns:\n",
    "            pr.PyRanges: PyRanges containing CDS features for the transcript.\n",
    "        \"\"\"\n",
    "        cds = self.gr[(self.gr.Feature == \"CDS\") & (self.gr.transcript_id == transcript_id)]\n",
    "        if len(cds) == 0:\n",
    "            logging.warning(f\"No CDS features found for transcript {transcript_id}.\")\n",
    "        return cds\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_utr(self, transcript_id: str, utr_type: str = None) -> pr.PyRanges:\n",
    "        \"\"\"\n",
    "        Returns a PyRanges of UTR features for the given transcript.\n",
    "        Optionally specify '5UTR' or '3UTR' to filter further.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to filter on.\n",
    "            utr_type (str, optional): If '5UTR', return only 5' UTR;\n",
    "                                      if '3UTR', return only 3' UTR;\n",
    "                                      otherwise return all UTR features.\n",
    "\n",
    "        Returns:\n",
    "            pr.PyRanges: PyRanges containing UTR features for the transcript.\n",
    "        \"\"\"\n",
    "        utr = self.gr[(self.gr.Feature.str.contains(\"UTR\", na=False)) & (self.gr.transcript_id == transcript_id)]\n",
    "        if utr_type == \"5UTR\":\n",
    "            utr = utr[utr.Feature == \"5UTR\"]\n",
    "        elif utr_type == \"3UTR\":\n",
    "            utr = utr[utr.Feature == \"3UTR\"]\n",
    "\n",
    "        if len(utr) == 0:\n",
    "            logging.warning(f\"No UTR features found for transcript {transcript_id} (type={utr_type}).\")\n",
    "        return utr\n",
    "\n",
    "    def get_intron_ranges(self, transcript_id: str) -> pr.PyRanges:\n",
    "        \"\"\"\n",
    "        Compute intron ranges by subtracting exons from the entire transcript range.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to filter on.\n",
    "\n",
    "        Returns:\n",
    "            pr.PyRanges: PyRanges containing intron coordinates.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return pr.PyRanges()\n",
    "\n",
    "        df_exons = exons.df\n",
    "        chrom = df_exons[\"Chromosome\"].iloc[0]\n",
    "        strand = df_exons[\"Strand\"].iloc[0]\n",
    "\n",
    "        start_min = df_exons[\"Start\"].min()\n",
    "        end_max = df_exons[\"End\"].max()\n",
    "\n",
    "        transcript_range = pr.PyRanges(\n",
    "            pd.DataFrame({\n",
    "                \"Chromosome\": [chrom],\n",
    "                \"Start\": [start_min],\n",
    "                \"End\": [end_max],\n",
    "                \"Strand\": [strand]\n",
    "            })\n",
    "        )\n",
    "        introns = transcript_range.subtract(exons)\n",
    "        return introns\n",
    "\n",
    "    def get_exon_coords_and_strand(self, transcript_id: str) -> Tuple[List[List[int]], Optional[int]]:\n",
    "        \"\"\"\n",
    "        Return exon coordinates and strand (+1 or -1) for a given transcript ID,\n",
    "        mimicking the style of the Ensembl API example (list of [end, start] pairs).\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            (exon_coord, strand):\n",
    "                exon_coord is a list of [end, start] pairs\n",
    "                strand is +1 or -1\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return ([], None)\n",
    "\n",
    "        df = exons.df.sort_values(by=\"Start\")\n",
    "        strand_symbol = df[\"Strand\"].iloc[0]  # '+' or '-'\n",
    "        strand = 1 if strand_symbol == '+' else -1\n",
    "\n",
    "        exon_coord = [[row.End, row.Start] for _, row in df.iterrows()]\n",
    "        return (exon_coord, strand)\n",
    "\n",
    "    def get_transcript_length(self, transcript_id: str) -> int:\n",
    "        \"\"\"\n",
    "        Return the total length of exons for the given transcript.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            int: Sum of all exon lengths for this transcript.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return 0\n",
    "        df = exons.df\n",
    "        lengths = df[\"End\"] - df[\"Start\"]\n",
    "        return lengths.sum()\n",
    "\n",
    "    def get_chromosome(self, transcript_id: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Return the chromosome/contig name for the given transcript.\n",
    "        Assumes that all exons in this transcript are on the same chromosome.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            str or None: Chromosome name (e.g., 'chr1', '1', etc.) or None if not found.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return None\n",
    "        df = exons.df\n",
    "        return df[\"Chromosome\"].iloc[0]\n",
    "\n",
    "    def get_strand(self, transcript_id: str) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Return +1 or -1 for the transcript's strand.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            int or None: 1 or -1, or None if not found.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return None\n",
    "        df = exons.df\n",
    "        strand_symbol = df[\"Strand\"].iloc[0]\n",
    "        return 1 if strand_symbol == '+' else -1\n",
    "\n",
    "    def get_transcripts_by_gene_id(self, gene_id: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of transcript IDs associated with a given gene_id.\n",
    "\n",
    "        Args:\n",
    "            gene_id (str): The gene ID to search for.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Transcript IDs for that gene.\n",
    "        \"\"\"\n",
    "        df = self.gr.df\n",
    "        subset = df[df.gene_id == gene_id]\n",
    "        t_ids = subset[\"transcript_id\"].dropna().unique()\n",
    "        if len(t_ids) == 0:\n",
    "            logging.warning(f\"No transcripts found for gene ID {gene_id}.\")\n",
    "        return list(t_ids)\n",
    "\n",
    "    def get_transcripts_by_gene_name(self, gene_name: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of transcript IDs associated with a given gene_name.\n",
    "\n",
    "        Args:\n",
    "            gene_name (str): The gene name to search for (e.g. BRCA1).\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Transcript IDs for that gene.\n",
    "        \"\"\"\n",
    "        df = self.gr.df\n",
    "        if \"gene_name\" not in df.columns:\n",
    "            logging.warning(\"No 'gene_name' column in GTF; cannot filter by gene name.\")\n",
    "            return []\n",
    "        subset = df[df.gene_name == gene_name]\n",
    "        t_ids = subset[\"transcript_id\"].dropna().unique()\n",
    "        if len(t_ids) == 0:\n",
    "            logging.warning(f\"No transcripts found for gene name {gene_name}.\")\n",
    "        return list(t_ids)\n",
    "\n",
    "    def get_exons_batch(self, transcript_ids: List[str]) -> Dict[str, pr.PyRanges]:\n",
    "        \"\"\"\n",
    "        Return a dict of transcript_id -> exons PyRanges for a list of transcript IDs.\n",
    "        Useful for batch queries.\n",
    "\n",
    "        Args:\n",
    "            transcript_ids (list of str): List of transcript IDs to fetch.\n",
    "\n",
    "        Returns:\n",
    "            dict: {transcript_id: PyRanges}\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for tid in transcript_ids:\n",
    "            result[tid] = self.get_exons(tid)\n",
    "        return result\n",
    "\n",
    "    def get_exon_coords_and_strand_batch(self, transcript_ids: List[str]) -> Dict[str, Tuple[List[List[int]], Optional[int]]]:\n",
    "        \"\"\"\n",
    "        Return a dict of transcript_id -> (exon_coord, strand), for batch querying.\n",
    "\n",
    "        Args:\n",
    "            transcript_ids (list of str): Transcript IDs to fetch.\n",
    "\n",
    "        Returns:\n",
    "            dict: {transcript_id: ([ [end, start], ... ], strand) }\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for tid in transcript_ids:\n",
    "            result[tid] = self.get_exon_coords_and_strand(tid)\n",
    "        return result\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # NEW FEATURE (1): Sequence Extraction\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def get_cds_sequence(self,\n",
    "                         transcript_id: str,\n",
    "                         reference_fasta: Optional[str] = None\n",
    "                         ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Return the nucleotide sequence of the CDS for a given transcript.\n",
    "        If reference_fasta is not provided, the method will use self.reference_fasta,\n",
    "        or prompt the user if that is also None.\n",
    "\n",
    "        Requires pyfaidx and a valid reference FASTA.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "            reference_fasta (str, optional): Path to the reference genome FASTA file.\n",
    "\n",
    "        Returns:\n",
    "            str or None: Nucleotide sequence of the CDS, or None if no CDS found.\n",
    "        \"\"\"\n",
    "        if Fasta is None:\n",
    "            logging.error(\"pyfaidx is not installed. Cannot extract sequences.\")\n",
    "            return None\n",
    "\n",
    "        # If no explicit FASTA was passed, fallback to the instance-level FASTA\n",
    "        if reference_fasta is None:\n",
    "            if self.reference_fasta:\n",
    "                reference_fasta = self.reference_fasta\n",
    "            else:\n",
    "                reference_fasta = input(\"Please provide path to the reference genome FASTA file: \")\n",
    "\n",
    "        cds = self.get_cds(transcript_id)\n",
    "        if len(cds) == 0:\n",
    "            logging.warning(f\"No CDS found for transcript {transcript_id}.\")\n",
    "            return None\n",
    "\n",
    "        # Open reference FASTA\n",
    "        fa = Fasta(reference_fasta)\n",
    "\n",
    "        # Sort CDS features by genomic position (important if multiple exons)\n",
    "        df = cds.df.sort_values(by=\"Start\")\n",
    "\n",
    "        # Extract sequence pieces and concatenate\n",
    "        seq_pieces = []\n",
    "        for _, row in df.iterrows():\n",
    "            chrom = row[\"Chromosome\"]\n",
    "            start = row[\"Start\"]\n",
    "            end = row[\"End\"]\n",
    "            strand = row[\"Strand\"]\n",
    "\n",
    "            piece = fa[chrom][start:end].seq\n",
    "            if strand == \"-\":\n",
    "                # Reverse complement if negative strand\n",
    "                piece = self._revcomp(piece)\n",
    "            seq_pieces.append(piece)\n",
    "\n",
    "        return \"\".join(seq_pieces)\n",
    "\n",
    "    def get_protein_sequence(self,\n",
    "                             transcript_id: str,\n",
    "                             reference_fasta: Optional[str] = None\n",
    "                             ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Return the translated protein sequence (in one-letter code) for a given transcriptâ€™s CDS.\n",
    "        If reference_fasta is not provided, the method will use self.reference_fasta,\n",
    "        or prompt the user if that is also None.\n",
    "\n",
    "        Requires pyfaidx and a valid reference FASTA.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "            reference_fasta (str, optional): Path to the reference genome FASTA file.\n",
    "\n",
    "        Returns:\n",
    "            str or None: Amino acid sequence, or None if no CDS is found.\n",
    "        \"\"\"\n",
    "        cds_seq = self.get_cds_sequence(transcript_id, reference_fasta)\n",
    "        if cds_seq is None:\n",
    "            return None\n",
    "\n",
    "        codon_table = self._get_standard_codon_table()\n",
    "        protein = []\n",
    "        for i in range(0, len(cds_seq), 3):\n",
    "            codon = cds_seq[i : i + 3]\n",
    "            if len(codon) < 3:\n",
    "                break  # incomplete codon\n",
    "            aa = codon_table.get(codon, \"X\")  # unknown => 'X'\n",
    "            if aa == \"*\":  # stop codon\n",
    "                break\n",
    "            protein.append(aa)\n",
    "        return \"\".join(protein)\n",
    "\n",
    "    def _revcomp(self, seq: str) -> str:\n",
    "        \"\"\"\n",
    "        Return the reverse-complement of a nucleotide sequence.\n",
    "        \"\"\"\n",
    "        complement = {\n",
    "            \"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\",\n",
    "            \"a\": \"t\", \"c\": \"g\", \"g\": \"c\", \"t\": \"a\",\n",
    "            \"N\": \"N\", \"n\": \"n\"\n",
    "        }\n",
    "        rev = []\n",
    "        for base in reversed(seq):\n",
    "            rev.append(complement.get(base, \"N\"))\n",
    "        return \"\".join(rev)\n",
    "\n",
    "    def _get_standard_codon_table(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Return a minimal codon table mapping triplets to single-letter amino acids.\n",
    "        Stop codon => '*'\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"ATA\":\"I\",\"ATC\":\"I\",\"ATT\":\"I\",\"ATG\":\"M\",\"ACA\":\"T\",\"ACC\":\"T\",\"ACG\":\"T\",\"ACT\":\"T\",\n",
    "            \"AAC\":\"N\",\"AAT\":\"N\",\"AAA\":\"K\",\"AAG\":\"K\",\"AGC\":\"S\",\"AGT\":\"S\",\"AGA\":\"R\",\"AGG\":\"R\",\n",
    "            \"CTA\":\"L\",\"CTC\":\"L\",\"CTG\":\"L\",\"CTT\":\"L\",\"CCA\":\"P\",\"CCC\":\"P\",\"CCG\":\"P\",\"CCT\":\"P\",\n",
    "            \"CAC\":\"H\",\"CAT\":\"H\",\"CAA\":\"Q\",\"CAG\":\"Q\",\"CGA\":\"R\",\"CGC\":\"R\",\"CGG\":\"R\",\"CGT\":\"R\",\n",
    "            \"GTA\":\"V\",\"GTC\":\"V\",\"GTG\":\"V\",\"GTT\":\"V\",\"GCA\":\"A\",\"GCC\":\"A\",\"GCG\":\"A\",\"GCT\":\"A\",\n",
    "            \"GAC\":\"D\",\"GAT\":\"D\",\"GAA\":\"E\",\"GAG\":\"E\",\"GGA\":\"G\",\"GGC\":\"G\",\"GGG\":\"G\",\"GGT\":\"G\",\n",
    "            \"TCA\":\"S\",\"TCC\":\"S\",\"TCG\":\"S\",\"TCT\":\"S\",\"TTC\":\"F\",\"TTT\":\"F\",\"TTA\":\"L\",\"TTG\":\"L\",\n",
    "            \"TAC\":\"Y\",\"TAT\":\"Y\",\"TAA\":\"*\",\"TAG\":\"*\",\"TGC\":\"C\",\"TGT\":\"C\",\"TGA\":\"*\",\"TGG\":\"W\"\n",
    "        }\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # NEW FEATURE (2): Alternative Splicing Analysis\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def get_splice_junctions(self, transcript_id: str) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Return the genomic start/end positions for each splice junction\n",
    "        (the exon-exon boundaries) for a given transcript.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[int, int]]: List of (donor_site, acceptor_site) for each splice junction.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) < 2:\n",
    "            logging.info(f\"Transcript {transcript_id} has fewer than 2 exons; no internal junctions.\")\n",
    "            return []\n",
    "\n",
    "        df_exons = exons.df.sort_values(by=\"Start\")\n",
    "        junctions = []\n",
    "        for i in range(len(df_exons) - 1):\n",
    "            exon_end = df_exons.iloc[i][\"End\"]\n",
    "            next_exon_start = df_exons.iloc[i + 1][\"Start\"]\n",
    "            junctions.append((exon_end, next_exon_start))\n",
    "\n",
    "        return junctions\n",
    "\n",
    "    def compare_transcripts_across_gene(self, gene_id: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compare exons of all transcripts for a given gene.\n",
    "        Returns a DataFrame of all exons grouped by transcript ID,\n",
    "        so you can quickly see which exons are shared or unique across isoforms.\n",
    "\n",
    "        Args:\n",
    "            gene_id (str): The gene ID to compare.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A dataframe with columns\n",
    "                          [transcript_id, Chromosome, Start, End, Strand].\n",
    "        \"\"\"\n",
    "        tid_list = self.get_transcripts_by_gene_id(gene_id)\n",
    "        if not tid_list:\n",
    "            logging.warning(f\"No transcripts found for gene {gene_id}.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        all_exons = []\n",
    "        for tid in tid_list:\n",
    "            exons = self.get_exons(tid)\n",
    "            if len(exons) == 0:\n",
    "                continue\n",
    "            df_exons = exons.df.copy()\n",
    "            df_exons[\"transcript_id\"] = tid\n",
    "            all_exons.append(\n",
    "                df_exons[[\"transcript_id\", \"Chromosome\", \"Start\", \"End\", \"Strand\"]]\n",
    "            )\n",
    "\n",
    "        if not all_exons:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        result = pd.concat(all_exons, ignore_index=True)\n",
    "        result.sort_values(by=[\"transcript_id\", \"Start\"], inplace=True)\n",
    "        return result\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Junction Chain Interpretation\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def get_junction_chain_signature(self, transcript_id: str) -> Optional[Tuple[Tuple[int, int], ...]]:\n",
    "        \"\"\"\n",
    "        Return a tuple of (exon_end, next_exon_start) pairs for each splice junction\n",
    "        in the given transcript. This provides a 'signature' to compare across\n",
    "        transcripts to see if they have the same junction chain.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            tuple of (int, int) or None:\n",
    "                A tuple of (end_of_exon_i, start_of_exon_(i+1)) for i in [0..n_exons-2].\n",
    "                Returns None if fewer than 2 exons (no internal junctions).\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) < 2:\n",
    "            logging.info(f\"Transcript {transcript_id} has fewer than 2 exons; no junction chain.\")\n",
    "            return None\n",
    "\n",
    "        df_exons = exons.df.sort_values(by=\"Start\")\n",
    "        junctions = []\n",
    "        for i in range(len(df_exons) - 1):\n",
    "            exon_end = df_exons.iloc[i][\"End\"]\n",
    "            next_exon_start = df_exons.iloc[i + 1][\"Start\"]\n",
    "            junctions.append((exon_end, next_exon_start))\n",
    "\n",
    "        return tuple(junctions)\n",
    "\n",
    "    def interpret_unique_junction_chains(self, gene_id: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Group transcripts of a given gene by their unique junction chain signatures.\n",
    "        This helps identify which isoforms share the exact same exon-exon boundaries\n",
    "        and which are unique.\n",
    "\n",
    "        Args:\n",
    "            gene_id (str): The gene ID to analyze.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame:\n",
    "                Columns:\n",
    "                  - 'junction_chain_signature': The tuple of (exon_end, next_exon_start) pairs.\n",
    "                  - 'transcript_count': How many transcripts share this chain.\n",
    "                  - 'transcripts': A list of transcript IDs that have this chain.\n",
    "        \"\"\"\n",
    "        tid_list = self.get_transcripts_by_gene_id(gene_id)\n",
    "        if not tid_list:\n",
    "            logging.warning(f\"No transcripts found for gene {gene_id}.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        chain_map = {}  # {chain_signature: [transcript_1, transcript_2, ...]}\n",
    "\n",
    "        for tid in tid_list:\n",
    "            signature = self.get_junction_chain_signature(tid)\n",
    "            if signature is None:  # e.g., single-exon transcripts\n",
    "                continue\n",
    "            chain_map.setdefault(signature, []).append(tid)\n",
    "\n",
    "        rows = []\n",
    "        for chain_sig, transcripts in chain_map.items():\n",
    "            rows.append({\n",
    "                \"junction_chain_signature\": chain_sig,\n",
    "                \"transcript_count\": len(transcripts),\n",
    "                \"transcripts\": transcripts\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.sort_values(\"transcript_count\", ascending=False, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def get_gene_names_for_transcripts(self, transcript_ids: List[str], ignore_after_period: bool = True, alternative_column: Optional[str] = None) -> List[Optional[str]]:\n",
    "        \"\"\"\n",
    "        Given a list of transcript IDs, return a list of the same length\n",
    "        where each element is the corresponding gene name or alternative column value from the GTF.\n",
    "        If a transcript is not found or if the target column is not available in the GTF,\n",
    "        the result will contain None for that transcript.\n",
    "\n",
    "        Args:\n",
    "            transcript_ids (List[str]): A list of transcript IDs.\n",
    "            ignore_after_period (bool): If True, strip the version suffix after the period.\n",
    "            alternative_column (Optional[str]): If provided, use this column in place of 'gene_name'.\n",
    "\n",
    "        Returns:\n",
    "            List[Optional[str]]: A parallel list of gene names (or alternative column values) or None.\n",
    "        \"\"\"\n",
    "        # Optionally strip the version suffix using regex\n",
    "        if ignore_after_period:\n",
    "            transcript_ids = [re.sub(r\"\\.\\d+$\", \"\", tid) for tid in transcript_ids]\n",
    "\n",
    "        df = self.gr.df\n",
    "        target_column = alternative_column if alternative_column is not None else \"gene_name\"\n",
    "        \n",
    "        if target_column not in df.columns:\n",
    "            logging.warning(f\"No '{target_column}' column in GTF; cannot retrieve gene names.\")\n",
    "            return [None] * len(transcript_ids)\n",
    "\n",
    "        # Filter to only the rows with the requested transcript IDs\n",
    "        subset = df[df.transcript_id.isin(transcript_ids)]\n",
    "\n",
    "        # Build a dict: transcript_id -> list of unique values from the target column in the annotation\n",
    "        mapping = (\n",
    "            subset\n",
    "            .groupby(\"transcript_id\")[target_column]\n",
    "            .apply(lambda x: list(x.unique()))\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        # For each transcript in the input, pick the first value from the mapping\n",
    "        result = []\n",
    "        for tid in transcript_ids:\n",
    "            possible_names = mapping.get(tid, [])\n",
    "            if possible_names:\n",
    "                result.append(possible_names[0])\n",
    "            else:\n",
    "                result.append(None)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def get_transcript_info(self, transcript_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Return a dictionary with basic info about the given transcript, including:\n",
    "        - transcript_id\n",
    "        - transcript_name (if available in the GTF, else \"unknown\")\n",
    "        - transcript_type (if available in the GTF, else \"unknown\")\n",
    "        - cds_start, cds_end (based on min/max of CDS ranges if present, else None)\n",
    "        - chromosome\n",
    "        - strand (either '+' or '-')\n",
    "        \"\"\"\n",
    "        df = self.gr.df\n",
    "        sub = df[df.transcript_id == transcript_id]\n",
    "\n",
    "        # If we didn't find this transcript at all, return an empty dict or raise an error.\n",
    "        if sub.empty:\n",
    "            logging.warning(f\"Transcript {transcript_id} not found in GTF.\")\n",
    "            return {}\n",
    "\n",
    "        # Pull transcript_name, transcript_type from columns if they exist\n",
    "        # (these column names vary in different GTF sources).\n",
    "        if \"transcript_name\" in sub.columns:\n",
    "            transcript_name = sub[\"transcript_name\"].dropna().unique()\n",
    "            if len(transcript_name) > 0:\n",
    "                transcript_name = transcript_name[0]\n",
    "            else:\n",
    "                transcript_name = \"unknown\"\n",
    "        else:\n",
    "            transcript_name = \"unknown\"\n",
    "        \n",
    "        if \"transcript_type\" in sub.columns:\n",
    "            transcript_type = sub[\"transcript_type\"].dropna().unique()\n",
    "            if len(transcript_type) > 0:\n",
    "                transcript_type = transcript_type[0]\n",
    "            else:\n",
    "                transcript_type = \"unknown\"\n",
    "        else:\n",
    "            transcript_type = \"unknown\"\n",
    "\n",
    "        # Derive chromosome and strand from any row of this transcript\n",
    "        # (assuming a consistent chromosome/strand for all features).\n",
    "        chromosome = str(sub[\"Chromosome\"].iloc[0])\n",
    "        strand_symbol = str(sub[\"Strand\"].iloc[0])  # '+' or '-'\n",
    "\n",
    "        # Compute the CDS boundaries using our existing get_cds() method.\n",
    "        cds_ranges = self.get_cds(transcript_id)\n",
    "        if len(cds_ranges) > 0:\n",
    "            cds_df = cds_ranges.df\n",
    "            cds_start = int(cds_df[\"Start\"].min())\n",
    "            cds_end = int(cds_df[\"End\"].max())\n",
    "        else:\n",
    "            cds_start = None\n",
    "            cds_end = None\n",
    "\n",
    "        return {\n",
    "            \"transcript_id\": transcript_id,\n",
    "            \"transcript_name\": transcript_name,\n",
    "            \"transcript_type\": transcript_type,\n",
    "            \"cds_start\": cds_start,\n",
    "            \"cds_end\": cds_end,\n",
    "            \"chromosome\": chromosome,\n",
    "            \"strand\": strand_symbol\n",
    "        }\n",
    "        \n",
    "    def get_exon_psi_matrix(self,\n",
    "                            gene_name: Optional[str] = None,\n",
    "                            transcript_ids: Optional[List[str]] = None,\n",
    "                            transcript_counts: Union[Dict[str, float], pd.DataFrame] = None\n",
    "                            ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compute an exon PSI (percent spliced in) matrix for a gene or a given list of transcript IDs.\n",
    "        For each unique exon (defined by Chromosome, Start, End, and Strand) among the transcripts,\n",
    "        the PSI is calculated as:\n",
    "        \n",
    "            PSI = (sum of counts for transcripts including the exon) / (total counts for all transcripts)\n",
    "        \n",
    "        Args:\n",
    "            gene_name (str, optional): If provided, transcripts for this gene are retrieved.\n",
    "            transcript_ids (List[str], optional): List of transcript IDs.\n",
    "                Ignored if gene_name is provided.\n",
    "            transcript_counts (dict or pd.DataFrame): Transcript-level counts.\n",
    "                If a dict is provided, it is assumed to map transcript_id -> count (single-sample).\n",
    "                If a DataFrame is provided, its index should be transcript_ids and its columns\n",
    "                represent different samples.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame where each row corresponds to a unique exon, with columns:\n",
    "                - 'Chromosome', 'Start', 'End', 'Strand'\n",
    "                - For a dict input: a column 'psi' (a value in [0,1])\n",
    "                - For a DataFrame input: one column per sample (named 'psi_{sample}')\n",
    "                - 'included_transcripts': the list of transcripts that include this exon.\n",
    "        \"\"\"\n",
    "        if gene_name is not None:\n",
    "            transcript_ids = self.get_transcripts_by_gene_name(gene_name)\n",
    "            if not transcript_ids:\n",
    "                logging.warning(f\"No transcripts found for gene name {gene_name}.\")\n",
    "                return pd.DataFrame()\n",
    "        elif transcript_ids is None:\n",
    "            logging.error(\"Either gene_name or transcript_ids must be provided.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Process transcript_counts\n",
    "        if transcript_counts is None:\n",
    "            logging.error(\"You must provide transcript_counts for PSI computation.\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        is_multi_sample = isinstance(transcript_counts, pd.DataFrame)\n",
    "        if not is_multi_sample:\n",
    "            if isinstance(transcript_counts, dict):\n",
    "                counts_series = pd.Series(transcript_counts)\n",
    "            else:\n",
    "                logging.error(\"transcript_counts must be a dict or a DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "            # Keep only transcripts in the provided list\n",
    "            counts_series = counts_series[counts_series.index.isin(transcript_ids)]\n",
    "            total_counts = counts_series.sum()\n",
    "        else:\n",
    "            counts_df = transcript_counts.loc[transcript_counts.index.intersection(transcript_ids)]\n",
    "            if counts_df.empty:\n",
    "                logging.error(\"No transcript counts found for the provided transcript IDs.\")\n",
    "                return pd.DataFrame()\n",
    "            total_counts = counts_df.sum()  # Series: sample -> total count\n",
    "        \n",
    "        # Build a mapping from unique exon coordinates to the set of transcript IDs that include it.\n",
    "        exon_mapping = {}\n",
    "        for tid in transcript_ids:\n",
    "            try:\n",
    "                exons = self.get_exons(tid)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Error retrieving exons for transcript {tid}: {e}\")\n",
    "                continue\n",
    "            if len(exons) == 0:\n",
    "                continue\n",
    "            # Iterate over each exon in this transcript\n",
    "            for _, row in exons.df.iterrows():\n",
    "                key = (row[\"Chromosome\"], row[\"Start\"], row[\"End\"], row[\"Strand\"])\n",
    "                exon_mapping.setdefault(key, set()).add(tid)\n",
    "        \n",
    "        # For each unique exon, compute its PSI value(s)\n",
    "        rows = []\n",
    "        for exon_key, tid_set in exon_mapping.items():\n",
    "            row_data = {\"Chromosome\": exon_key[0],\n",
    "                        \"Start\": exon_key[1],\n",
    "                        \"End\": exon_key[2],\n",
    "                        \"Strand\": exon_key[3]}\n",
    "            if is_multi_sample:\n",
    "                # Sum counts over transcripts that include this exon for each sample\n",
    "                included_counts = counts_df.loc[counts_df.index.intersection(list(tid_set))].sum()\n",
    "                psi_dict = {}\n",
    "                for sample in counts_df.columns:\n",
    "                    tot = total_counts[sample]\n",
    "                    psi = included_counts[sample] / tot if tot != 0 else np.nan\n",
    "                    psi_dict[f\"psi_{sample}\"] = psi\n",
    "                row_data.update(psi_dict)\n",
    "            else:\n",
    "                included_counts = counts_series[counts_series.index.isin(list(tid_set))].sum()\n",
    "                psi = included_counts / total_counts if total_counts != 0 else np.nan\n",
    "                row_data[\"psi\"] = psi\n",
    "            row_data[\"included_transcripts\"] = list(tid_set)\n",
    "            rows.append(row_data)\n",
    "        \n",
    "        psi_df = pd.DataFrame(rows)\n",
    "        psi_df.sort_values([\"Chromosome\", \"Start\"], inplace=True)\n",
    "        return psi_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae39e82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exons: +--------------+----------------+------------+-----------+-------+\n",
      "|   Chromosome | Source         | Feature    |     Start | +22   |\n",
      "|   (category) | (object)       | (object)   |   (int64) | ...   |\n",
      "|--------------+----------------+------------+-----------+-------|\n",
      "|            1 | ensembl_havana | exon       |   3740774 | ...   |\n",
      "|            1 | ensembl_havana | exon       |   3491924 | ...   |\n",
      "|            1 | ensembl_havana | exon       |   3284704 | ...   |\n",
      "+--------------+----------------+------------+-----------+-------+\n",
      "Stranded PyRanges object has 3 rows and 26 columns from 1 chromosomes.\n",
      "For printing, the PyRanges was sorted on Chromosome and Strand.\n",
      "22 hidden columns: End, Score, Strand, Frame, gene_id, gene_version, ... (+ 16 more.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Example Ensembl URLs for mouse GRCm39 (release 109)\n",
    "gtf_url = \"ftp://ftp.ensembl.org/pub/release-109/gtf/mus_musculus/Mus_musculus.GRCm39.109.gtf.gz\"\n",
    "fasta_url = \"ftp://ftp.ensembl.org/pub/release-109/fasta/mus_musculus/dna/Mus_musculus.GRCm39.dna.primary_assembly.fa.gz\"\n",
    "\n",
    "# Store data one directory back\n",
    "data_dir = Path(\"..\") / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gtf_file_local = data_dir / \"Mus_musculus.GRCm39.109.gtf.gz\"\n",
    "fasta_file_local = data_dir / \"Mus_musculus.GRCm39.dna.primary_assembly.fa.gz\"\n",
    "\n",
    "# Download if not already present\n",
    "if not gtf_file_local.is_file():\n",
    "    print(f\"Downloading {gtf_url}...\")\n",
    "    urllib.request.urlretrieve(gtf_url, gtf_file_local)\n",
    "\n",
    "if not fasta_file_local.is_file():\n",
    "    print(f\"Downloading {fasta_url}...\")\n",
    "    urllib.request.urlretrieve(fasta_url, fasta_file_local)\n",
    "\n",
    "# Instantiate your TranscriptData\n",
    "td = TranscriptData(\n",
    "    gtf_file=gtf_file_local,\n",
    "    reference_fasta=fasta_file_local\n",
    ")\n",
    "\n",
    "# Now you can make queries like:\n",
    "example_transcript_id = \"ENSMUST00000070533\"  # e.g., for mouse\n",
    "exons = td.get_exons(example_transcript_id)\n",
    "print(\"Exons:\", exons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3323cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = pr.read_gtf(gtf_file_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6055c4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Chromosome', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand',\n",
       "       'Frame', 'gene_id', 'gene_version', 'gene_name', 'gene_source',\n",
       "       'gene_biotype', 'transcript_id', 'transcript_version',\n",
       "       'transcript_name', 'transcript_source', 'transcript_biotype', 'tag',\n",
       "       'transcript_support_level', 'exon_number', 'exon_id', 'exon_version',\n",
       "       'ccds_id', 'protein_id', 'protein_version'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77404e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         NaN\n",
       "1          ENSMUST00000194081\n",
       "2          ENSMUST00000194081\n",
       "3                         NaN\n",
       "4          ENSMUST00000194393\n",
       "                  ...        \n",
       "1901233    ENSMUST00000189418\n",
       "1901234    ENSMUST00000189418\n",
       "1901235                   NaN\n",
       "1901236    ENSMUST00000186353\n",
       "1901237    ENSMUST00000186353\n",
       "Name: transcript_id, Length: 1901238, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges.as_df()['transcript_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e105ad36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Looking for file at: /data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/allos/resources/e18.mouse.clusters.csv\n",
      "âœ… File found at: /data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/allos/resources/e18.mouse.clusters.csv\n",
      "âœ… File already exists at: /data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/allos/resources/data/mouse_1.txt.gz\n",
      "\n",
      "ðŸ”„ Decompressing /data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/allos/resources/data/mouse_1.txt.gz to /data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/allos/resources/data/mouse_1.txt...\n",
      "âœ… Decompression complete.\n",
      "Test data (mouse_1) downloaded successfully\n",
      "âœ… File already exists at: /data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/allos/resources/data/mouse_2.txt.gz\n",
      "\n",
      "ðŸ”„ Decompressing /data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/allos/resources/data/mouse_2.txt.gz to /data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/allos/resources/data/mouse_2.txt...\n",
      "âœ… Decompression complete.\n",
      "Test data (mouse_2) downloaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/analysis/data_mcandrew/Allos_new/allos_env/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "from allos.readers_tests import *\n",
    "mouse_data = process_mouse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a61876f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptIds = mouse_data.var.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a73ca1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENSMUST00000156717.1',\n",
       " 'ENSMUST00000212520.1',\n",
       " 'ENSMUST00000025798.12',\n",
       " 'ENSMUST00000231280.1',\n",
       " 'ENSMUST00000039286.4',\n",
       " 'ENSMUST00000144552.7',\n",
       " 'ENSMUST00000112304.8',\n",
       " 'ENSMUST00000162041.7',\n",
       " 'ENSMUST00000053506.6',\n",
       " 'ENSMUST00000028207.12']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptIds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e1c71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = td.get_gene_names_for_transcripts(transcript_ids=transcriptIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172e5e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Klc2',\n",
       " 'Capn15',\n",
       " 'Klc2',\n",
       " 'Eva1c',\n",
       " 'Atg5',\n",
       " 'Znhit3',\n",
       " 'Ppm1b',\n",
       " 'Gcc2',\n",
       " 'Bbs1',\n",
       " 'Crat']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4763d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20851e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bee6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700fee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4cdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720a57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767e1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
