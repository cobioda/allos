{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf08f36060bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b873c4cbabc5169",
   "metadata": {},
   "outputs": [],
   "source": "#| default_exp transcript_plots"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import sys\n",
    "import patchworklib as pw\n",
    "import urllib\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gammaln\n",
    "from scipy.optimize import minimize\n",
    "from itertools import combinations\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "from functools import lru_cache\n",
    "import pyranges as pr\n",
    "from pyfaidx import Fasta\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05f3ea6565f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TranscriptData:\n",
    "    \"\"\"\n",
    "    A class for managing transcript and gene information from a GTF file using PyRanges.\n",
    "\n",
    "    Existing Features:\n",
    "      - Lookup by transcript ID or gene ID/name\n",
    "      - Support for exons, CDS, UTR queries\n",
    "      - Intron coordinate calculation\n",
    "      - Batch queries\n",
    "      - Transcript length calculation\n",
    "      - Caching/memoization for repeated queries\n",
    "      - Basic logging/error handling\n",
    "\n",
    "    NEW Features:\n",
    "      (1) Nucleotide/protein sequence retrieval for CDS (with optional FASTA)\n",
    "      (2) Alternative splicing analysis with splice junctions, isoform comparisons,\n",
    "          and junction-chain interpretation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gtf_file: str, reference_fasta: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Read the GTF file into a PyRanges object and store it.\n",
    "        Optionally store a path to a reference FASTA for sequence methods.\n",
    "\n",
    "        Args:\n",
    "            gtf_file (str): Path to a GTF/GFF file.\n",
    "            reference_fasta (str, optional): Path to a reference genome FASTA.\n",
    "        \"\"\"\n",
    "        self.gtf_file = gtf_file\n",
    "        self.reference_fasta = reference_fasta  # store for later use\n",
    "        logging.info(f\"Loading GTF from {gtf_file}. This may take a while...\")\n",
    "        try:\n",
    "            self.gr = pr.read_gtf(gtf_file)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading GTF file: {e}\")\n",
    "            raise\n",
    "        logging.info(\"GTF loaded successfully.\")\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_exons(self, transcript_id: str) -> pr.PyRanges:\n",
    "        \"\"\"\n",
    "        Returns a PyRanges of exons for the given transcript.\n",
    "        Results are cached for faster repeat lookups.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to filter on.\n",
    "\n",
    "        Returns:\n",
    "            pr.PyRanges: PyRanges containing exon features for the transcript.\n",
    "        \"\"\"\n",
    "        exons = self.gr[(self.gr.Feature == \"exon\") & (self.gr.transcript_id == transcript_id)]\n",
    "        if len(exons) == 0:\n",
    "            logging.warning(f\"No exons found for transcript {transcript_id}.\")\n",
    "        return exons\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_cds(self, transcript_id: str) -> pr.PyRanges:\n",
    "        \"\"\"\n",
    "        Returns a PyRanges of CDS features for the given transcript.\n",
    "        Results are cached for faster repeat lookups.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to filter on.\n",
    "\n",
    "        Returns:\n",
    "            pr.PyRanges: PyRanges containing CDS features for the transcript.\n",
    "        \"\"\"\n",
    "        cds = self.gr[(self.gr.Feature == \"CDS\") & (self.gr.transcript_id == transcript_id)]\n",
    "        if len(cds) == 0:\n",
    "            logging.warning(f\"No CDS features found for transcript {transcript_id}.\")\n",
    "        return cds\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_utr(self, transcript_id: str, utr_type: str = None) -> pr.PyRanges:\n",
    "        \"\"\"\n",
    "        Returns a PyRanges of UTR features for the given transcript.\n",
    "        Optionally specify '5UTR' or '3UTR' to filter further.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to filter on.\n",
    "            utr_type (str, optional): If '5UTR', return only 5' UTR;\n",
    "                                      if '3UTR', return only 3' UTR;\n",
    "                                      otherwise return all UTR features.\n",
    "\n",
    "        Returns:\n",
    "            pr.PyRanges: PyRanges containing UTR features for the transcript.\n",
    "        \"\"\"\n",
    "        utr = self.gr[(self.gr.Feature.str.contains(\"UTR\", na=False)) & (self.gr.transcript_id == transcript_id)]\n",
    "        if utr_type == \"5UTR\":\n",
    "            utr = utr[utr.Feature == \"5UTR\"]\n",
    "        elif utr_type == \"3UTR\":\n",
    "            utr = utr[utr.Feature == \"3UTR\"]\n",
    "\n",
    "        if len(utr) == 0:\n",
    "            logging.warning(f\"No UTR features found for transcript {transcript_id} (type={utr_type}).\")\n",
    "        return utr\n",
    "\n",
    "    def get_intron_ranges(self, transcript_id: str) -> pr.PyRanges:\n",
    "        \"\"\"\n",
    "        Compute intron ranges by subtracting exons from the entire transcript range.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to filter on.\n",
    "\n",
    "        Returns:\n",
    "            pr.PyRanges: PyRanges containing intron coordinates.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return pr.PyRanges()\n",
    "\n",
    "        df_exons = exons.df\n",
    "        chrom = df_exons[\"Chromosome\"].iloc[0]\n",
    "        strand = df_exons[\"Strand\"].iloc[0]\n",
    "\n",
    "        start_min = df_exons[\"Start\"].min()\n",
    "        end_max = df_exons[\"End\"].max()\n",
    "\n",
    "        transcript_range = pr.PyRanges(\n",
    "            pd.DataFrame({\n",
    "                \"Chromosome\": [chrom],\n",
    "                \"Start\": [start_min],\n",
    "                \"End\": [end_max],\n",
    "                \"Strand\": [strand]\n",
    "            })\n",
    "        )\n",
    "        introns = transcript_range.subtract(exons)\n",
    "        return introns\n",
    "\n",
    "    def get_exon_coords_and_strand(self, transcript_id: str) -> Tuple[List[List[int]], Optional[int]]:\n",
    "        \"\"\"\n",
    "        Return exon coordinates and strand (+1 or -1) for a given transcript ID,\n",
    "        mimicking the style of the Ensembl API example (list of [end, start] pairs).\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            (exon_coord, strand):\n",
    "                exon_coord is a list of [end, start] pairs\n",
    "                strand is +1 or -1\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return ([], None)\n",
    "\n",
    "        df = exons.df.sort_values(by=\"Start\")\n",
    "        strand_symbol = df[\"Strand\"].iloc[0]  # '+' or '-'\n",
    "        strand = 1 if strand_symbol == '+' else -1\n",
    "\n",
    "        exon_coord = [[row.End, row.Start] for _, row in df.iterrows()]\n",
    "        return (exon_coord, strand)\n",
    "\n",
    "    def get_transcript_length(self, transcript_id: str) -> int:\n",
    "        \"\"\"\n",
    "        Return the total length of exons for the given transcript.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            int: Sum of all exon lengths for this transcript.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return 0\n",
    "        df = exons.df\n",
    "        lengths = df[\"End\"] - df[\"Start\"]\n",
    "        return lengths.sum()\n",
    "\n",
    "    def get_chromosome(self, transcript_id: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Return the chromosome/contig name for the given transcript.\n",
    "        Assumes that all exons in this transcript are on the same chromosome.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            str or None: Chromosome name (e.g., 'chr1', '1', etc.) or None if not found.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return None\n",
    "        df = exons.df\n",
    "        return df[\"Chromosome\"].iloc[0]\n",
    "\n",
    "    def get_strand(self, transcript_id: str) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Return +1 or -1 for the transcript's strand.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            int or None: 1 or -1, or None if not found.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) == 0:\n",
    "            return None\n",
    "        df = exons.df\n",
    "        strand_symbol = df[\"Strand\"].iloc[0]\n",
    "        return 1 if strand_symbol == '+' else -1\n",
    "\n",
    "    def get_transcripts_by_gene_id(self, gene_id: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of transcript IDs associated with a given gene_id.\n",
    "\n",
    "        Args:\n",
    "            gene_id (str): The gene ID to search for.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Transcript IDs for that gene.\n",
    "        \"\"\"\n",
    "        df = self.gr.df\n",
    "        subset = df[df.gene_id == gene_id]\n",
    "        t_ids = subset[\"transcript_id\"].dropna().unique()\n",
    "        if len(t_ids) == 0:\n",
    "            logging.warning(f\"No transcripts found for gene ID {gene_id}.\")\n",
    "        return list(t_ids)\n",
    "\n",
    "    def get_transcripts_by_gene_name(self, gene_name: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of transcript IDs associated with a given gene_name.\n",
    "\n",
    "        Args:\n",
    "            gene_name (str): The gene name to search for (e.g. BRCA1).\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Transcript IDs for that gene.\n",
    "        \"\"\"\n",
    "        df = self.gr.df\n",
    "        if \"gene_name\" not in df.columns:\n",
    "            logging.warning(\"No 'gene_name' column in GTF; cannot filter by gene name.\")\n",
    "            return []\n",
    "        subset = df[df.gene_name == gene_name]\n",
    "        t_ids = subset[\"transcript_id\"].dropna().unique()\n",
    "        if len(t_ids) == 0:\n",
    "            logging.warning(f\"No transcripts found for gene name {gene_name}.\")\n",
    "        return list(t_ids)\n",
    "\n",
    "    def get_exons_batch(self, transcript_ids: List[str]) -> Dict[str, pr.PyRanges]:\n",
    "        \"\"\"\n",
    "        Return a dict of transcript_id -> exons PyRanges for a list of transcript IDs.\n",
    "        Useful for batch queries.\n",
    "\n",
    "        Args:\n",
    "            transcript_ids (list of str): List of transcript IDs to fetch.\n",
    "\n",
    "        Returns:\n",
    "            dict: {transcript_id: PyRanges}\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for tid in transcript_ids:\n",
    "            result[tid] = self.get_exons(tid)\n",
    "        return result\n",
    "\n",
    "    def get_exon_coords_and_strand_batch(self, transcript_ids: List[str]) -> Dict[str, Tuple[List[List[int]], Optional[int]]]:\n",
    "        \"\"\"\n",
    "        Return a dict of transcript_id -> (exon_coord, strand), for batch querying.\n",
    "\n",
    "        Args:\n",
    "            transcript_ids (list of str): Transcript IDs to fetch.\n",
    "\n",
    "        Returns:\n",
    "            dict: {transcript_id: ([ [end, start], ... ], strand) }\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for tid in transcript_ids:\n",
    "            result[tid] = self.get_exon_coords_and_strand(tid)\n",
    "        return result\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # NEW FEATURE (1): Sequence Extraction\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def get_cds_sequence(self,\n",
    "                         transcript_id: str,\n",
    "                         reference_fasta: Optional[str] = None\n",
    "                         ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Return the nucleotide sequence of the CDS for a given transcript.\n",
    "        If reference_fasta is not provided, the method will use self.reference_fasta,\n",
    "        or prompt the user if that is also None.\n",
    "\n",
    "        Requires pyfaidx and a valid reference FASTA.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "            reference_fasta (str, optional): Path to the reference genome FASTA file.\n",
    "\n",
    "        Returns:\n",
    "            str or None: Nucleotide sequence of the CDS, or None if no CDS found.\n",
    "        \"\"\"\n",
    "        if Fasta is None:\n",
    "            logging.error(\"pyfaidx is not installed. Cannot extract sequences.\")\n",
    "            return None\n",
    "\n",
    "        # If no explicit FASTA was passed, fallback to the instance-level FASTA\n",
    "        if reference_fasta is None:\n",
    "            if self.reference_fasta:\n",
    "                reference_fasta = self.reference_fasta\n",
    "            else:\n",
    "                reference_fasta = input(\"Please provide path to the reference genome FASTA file: \")\n",
    "\n",
    "        cds = self.get_cds(transcript_id)\n",
    "        if len(cds) == 0:\n",
    "            logging.warning(f\"No CDS found for transcript {transcript_id}.\")\n",
    "            return None\n",
    "\n",
    "        # Open reference FASTA\n",
    "        fa = Fasta(reference_fasta)\n",
    "\n",
    "        # Sort CDS features by genomic position (important if multiple exons)\n",
    "        df = cds.df.sort_values(by=\"Start\")\n",
    "\n",
    "        # Extract sequence pieces and concatenate\n",
    "        seq_pieces = []\n",
    "        for _, row in df.iterrows():\n",
    "            chrom = row[\"Chromosome\"]\n",
    "            start = row[\"Start\"]\n",
    "            end = row[\"End\"]\n",
    "            strand = row[\"Strand\"]\n",
    "\n",
    "            piece = fa[chrom][start:end].seq\n",
    "            if strand == \"-\":\n",
    "                # Reverse complement if negative strand\n",
    "                piece = self._revcomp(piece)\n",
    "            seq_pieces.append(piece)\n",
    "\n",
    "        return \"\".join(seq_pieces)\n",
    "\n",
    "    def get_protein_sequence(self,\n",
    "                             transcript_id: str,\n",
    "                             reference_fasta: Optional[str] = None\n",
    "                             ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Return the translated protein sequence (in one-letter code) for a given transcriptâ€™s CDS.\n",
    "        If reference_fasta is not provided, the method will use self.reference_fasta,\n",
    "        or prompt the user if that is also None.\n",
    "\n",
    "        Requires pyfaidx and a valid reference FASTA.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "            reference_fasta (str, optional): Path to the reference genome FASTA file.\n",
    "\n",
    "        Returns:\n",
    "            str or None: Amino acid sequence, or None if no CDS is found.\n",
    "        \"\"\"\n",
    "        cds_seq = self.get_cds_sequence(transcript_id, reference_fasta)\n",
    "        if cds_seq is None:\n",
    "            return None\n",
    "\n",
    "        codon_table = self._get_standard_codon_table()\n",
    "        protein = []\n",
    "        for i in range(0, len(cds_seq), 3):\n",
    "            codon = cds_seq[i : i + 3]\n",
    "            if len(codon) < 3:\n",
    "                break  # incomplete codon\n",
    "            aa = codon_table.get(codon, \"X\")  # unknown => 'X'\n",
    "            if aa == \"*\":  # stop codon\n",
    "                break\n",
    "            protein.append(aa)\n",
    "        return \"\".join(protein)\n",
    "\n",
    "    def _revcomp(self, seq: str) -> str:\n",
    "        \"\"\"\n",
    "        Return the reverse-complement of a nucleotide sequence.\n",
    "        \"\"\"\n",
    "        complement = {\n",
    "            \"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\",\n",
    "            \"a\": \"t\", \"c\": \"g\", \"g\": \"c\", \"t\": \"a\",\n",
    "            \"N\": \"N\", \"n\": \"n\"\n",
    "        }\n",
    "        rev = []\n",
    "        for base in reversed(seq):\n",
    "            rev.append(complement.get(base, \"N\"))\n",
    "        return \"\".join(rev)\n",
    "\n",
    "    def _get_standard_codon_table(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Return a minimal codon table mapping triplets to single-letter amino acids.\n",
    "        Stop codon => '*'\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"ATA\":\"I\",\"ATC\":\"I\",\"ATT\":\"I\",\"ATG\":\"M\",\"ACA\":\"T\",\"ACC\":\"T\",\"ACG\":\"T\",\"ACT\":\"T\",\n",
    "            \"AAC\":\"N\",\"AAT\":\"N\",\"AAA\":\"K\",\"AAG\":\"K\",\"AGC\":\"S\",\"AGT\":\"S\",\"AGA\":\"R\",\"AGG\":\"R\",\n",
    "            \"CTA\":\"L\",\"CTC\":\"L\",\"CTG\":\"L\",\"CTT\":\"L\",\"CCA\":\"P\",\"CCC\":\"P\",\"CCG\":\"P\",\"CCT\":\"P\",\n",
    "            \"CAC\":\"H\",\"CAT\":\"H\",\"CAA\":\"Q\",\"CAG\":\"Q\",\"CGA\":\"R\",\"CGC\":\"R\",\"CGG\":\"R\",\"CGT\":\"R\",\n",
    "            \"GTA\":\"V\",\"GTC\":\"V\",\"GTG\":\"V\",\"GTT\":\"V\",\"GCA\":\"A\",\"GCC\":\"A\",\"GCG\":\"A\",\"GCT\":\"A\",\n",
    "            \"GAC\":\"D\",\"GAT\":\"D\",\"GAA\":\"E\",\"GAG\":\"E\",\"GGA\":\"G\",\"GGC\":\"G\",\"GGG\":\"G\",\"GGT\":\"G\",\n",
    "            \"TCA\":\"S\",\"TCC\":\"S\",\"TCG\":\"S\",\"TCT\":\"S\",\"TTC\":\"F\",\"TTT\":\"F\",\"TTA\":\"L\",\"TTG\":\"L\",\n",
    "            \"TAC\":\"Y\",\"TAT\":\"Y\",\"TAA\":\"*\",\"TAG\":\"*\",\"TGC\":\"C\",\"TGT\":\"C\",\"TGA\":\"*\",\"TGG\":\"W\"\n",
    "        }\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # NEW FEATURE (2): Alternative Splicing Analysis\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def get_splice_junctions(self, transcript_id: str) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Return the genomic start/end positions for each splice junction\n",
    "        (the exon-exon boundaries) for a given transcript.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[int, int]]: List of (donor_site, acceptor_site) for each splice junction.\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) < 2:\n",
    "            logging.info(f\"Transcript {transcript_id} has fewer than 2 exons; no internal junctions.\")\n",
    "            return []\n",
    "\n",
    "        df_exons = exons.df.sort_values(by=\"Start\")\n",
    "        junctions = []\n",
    "        for i in range(len(df_exons) - 1):\n",
    "            exon_end = df_exons.iloc[i][\"End\"]\n",
    "            next_exon_start = df_exons.iloc[i + 1][\"Start\"]\n",
    "            junctions.append((exon_end, next_exon_start))\n",
    "\n",
    "        return junctions\n",
    "\n",
    "    def compare_transcripts_across_gene(self, gene_id: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compare exons of all transcripts for a given gene.\n",
    "        Returns a DataFrame of all exons grouped by transcript ID,\n",
    "        so you can quickly see which exons are shared or unique across isoforms.\n",
    "\n",
    "        Args:\n",
    "            gene_id (str): The gene ID to compare.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A dataframe with columns\n",
    "                          [transcript_id, Chromosome, Start, End, Strand].\n",
    "        \"\"\"\n",
    "        tid_list = self.get_transcripts_by_gene_id(gene_id)\n",
    "        if not tid_list:\n",
    "            logging.warning(f\"No transcripts found for gene {gene_id}.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        all_exons = []\n",
    "        for tid in tid_list:\n",
    "            exons = self.get_exons(tid)\n",
    "            if len(exons) == 0:\n",
    "                continue\n",
    "            df_exons = exons.df.copy()\n",
    "            df_exons[\"transcript_id\"] = tid\n",
    "            all_exons.append(\n",
    "                df_exons[[\"transcript_id\", \"Chromosome\", \"Start\", \"End\", \"Strand\"]]\n",
    "            )\n",
    "\n",
    "        if not all_exons:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        result = pd.concat(all_exons, ignore_index=True)\n",
    "        result.sort_values(by=[\"transcript_id\", \"Start\"], inplace=True)\n",
    "        return result\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Junction Chain Interpretation\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def get_junction_chain_signature(self, transcript_id: str) -> Optional[Tuple[Tuple[int, int], ...]]:\n",
    "        \"\"\"\n",
    "        Return a tuple of (exon_end, next_exon_start) pairs for each splice junction\n",
    "        in the given transcript. This provides a 'signature' to compare across\n",
    "        transcripts to see if they have the same junction chain.\n",
    "\n",
    "        Args:\n",
    "            transcript_id (str): The transcript ID to query.\n",
    "\n",
    "        Returns:\n",
    "            tuple of (int, int) or None:\n",
    "                A tuple of (end_of_exon_i, start_of_exon_(i+1)) for i in [0..n_exons-2].\n",
    "                Returns None if fewer than 2 exons (no internal junctions).\n",
    "        \"\"\"\n",
    "        exons = self.get_exons(transcript_id)\n",
    "        if len(exons) < 2:\n",
    "            logging.info(f\"Transcript {transcript_id} has fewer than 2 exons; no junction chain.\")\n",
    "            return None\n",
    "\n",
    "        df_exons = exons.df.sort_values(by=\"Start\")\n",
    "        junctions = []\n",
    "        for i in range(len(df_exons) - 1):\n",
    "            exon_end = df_exons.iloc[i][\"End\"]\n",
    "            next_exon_start = df_exons.iloc[i + 1][\"Start\"]\n",
    "            junctions.append((exon_end, next_exon_start))\n",
    "\n",
    "        return tuple(junctions)\n",
    "\n",
    "    def interpret_unique_junction_chains(self, gene_id: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Group transcripts of a given gene by their unique junction chain signatures.\n",
    "        This helps identify which isoforms share the exact same exon-exon boundaries\n",
    "        and which are unique.\n",
    "\n",
    "        Args:\n",
    "            gene_id (str): The gene ID to analyze.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame:\n",
    "                Columns:\n",
    "                  - 'junction_chain_signature': The tuple of (exon_end, next_exon_start) pairs.\n",
    "                  - 'transcript_count': How many transcripts share this chain.\n",
    "                  - 'transcripts': A list of transcript IDs that have this chain.\n",
    "        \"\"\"\n",
    "        tid_list = self.get_transcripts_by_gene_id(gene_id)\n",
    "        if not tid_list:\n",
    "            logging.warning(f\"No transcripts found for gene {gene_id}.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        chain_map = {}  # {chain_signature: [transcript_1, transcript_2, ...]}\n",
    "\n",
    "        for tid in tid_list:\n",
    "            signature = self.get_junction_chain_signature(tid)\n",
    "            if signature is None:  # e.g., single-exon transcripts\n",
    "                continue\n",
    "            chain_map.setdefault(signature, []).append(tid)\n",
    "\n",
    "        rows = []\n",
    "        for chain_sig, transcripts in chain_map.items():\n",
    "            rows.append({\n",
    "                \"junction_chain_signature\": chain_sig,\n",
    "                \"transcript_count\": len(transcripts),\n",
    "                \"transcripts\": transcripts\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.sort_values(\"transcript_count\", ascending=False, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a625888b908b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TranscriptPlots:\n",
    "    def __init__(self, gtf_file=None, reference_fasta=None):\n",
    "        self.transcript_data = None\n",
    "        if gtf_file is not None:\n",
    "            self.transcript_data = TranscriptData(gtf_file=gtf_file, reference_fasta=reference_fasta)\n",
    "\n",
    "    def get_transcript_info(self, transcript_id):\n",
    "        if self.transcript_data is None:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        data_dict = dict()\n",
    "        keys = ['transcript_id', 'transcript_name', 'transcript_type', 'cds_start', 'cds_end', 'chromosome', 'strand']\n",
    "        for key in keys:\n",
    "            data_dict[key] = 0\n",
    "        data_dict['cds_end'] = -sys.maxsize\n",
    "        data_dict['cds_start'] = sys.maxsize\n",
    "        cds = self.transcript_data.get_cds(transcript_id)\n",
    "        df = cds.df.sort_values(by=\"Start\")\n",
    "        for _, row in df.iterrows():\n",
    "            data_dict['transcript_id'] = row[\"transcript_id\"]\n",
    "            data_dict['transcript_name'] = row[\"transcript_name\"]\n",
    "            data_dict['transcript_type'] = row[\"transcript_type\"]\n",
    "            data_dict['cds_start'] = min(row[\"Start\"], data_dict['cds_start'])\n",
    "            data_dict['cds_end'] = max(row[\"Start\"], data_dict['cds_end'])\n",
    "            data_dict['chromosome'] = row[\"Chromosome\"]\n",
    "            data_dict['strand'] = row[\"Strand\"]\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "    def _get_coord_from_tscrpt_id(self, transcript_id):\n",
    "        if self.transcript_data is None:\n",
    "            if '.' in transcript_id:\n",
    "                transcript_id = transcript_id.split('.')[0]\n",
    "            server = \"https://rest.ensembl.org\"\n",
    "            ext = \"/lookup/id/\" + transcript_id + \"?expand=1\"\n",
    "\n",
    "            r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    "\n",
    "            if not r.ok:\n",
    "                r.raise_for_status()\n",
    "                sys.exit()\n",
    "\n",
    "            decoded = r.json()\n",
    "            exon_list = list(decoded['Exon'])\n",
    "            exon_coord = []\n",
    "            for i, e in enumerate(exon_list):\n",
    "                coord = [e.get('end'), e.get('start')]\n",
    "                exon_coord.append(coord)\n",
    "            strand = decoded['strand']\n",
    "            return(exon_coord, strand)\n",
    "        else:\n",
    "            return self.transcript_data.get_exon_coords_and_strand(transcript_id)\n",
    "\n",
    "    def _draw_transcript(self, exons, direction, color, transcript_name, offset=0, start_override=None, end_override=None, no_render=False):\n",
    "        if not no_render:\n",
    "            plt.axes()\n",
    "            plt.xlim((-0.1, 1))\n",
    "            plt.ylim((-0.3, 0.3))\n",
    "            plt.margins(0.2)\n",
    "            plt.axis('off')\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(20, 2)\n",
    "        height = 0.2\n",
    "        plt.plot([offset + 0.1, offset + 0.1], linestyle='solid', linewidth=0.5, c='grey')\n",
    "        j = 0\n",
    "        k = 1\n",
    "        if direction == 1:\n",
    "            pos_start = exons[0][1]\n",
    "            pos_end = exons[-1][0]\n",
    "        else: #direction == -1\n",
    "            pos_start = exons[-1][1]\n",
    "            pos_end = exons[0][0]\n",
    "            j = 1\n",
    "            k = 0\n",
    "        real_start = pos_start\n",
    "        real_end = pos_end\n",
    "        if start_override is not None and end_override is not None:\n",
    "            pos_start = start_override\n",
    "            pos_end = end_override\n",
    "        total_length = pos_end - pos_start\n",
    "        total_length_with_margin = 1.05 * total_length\n",
    "        pos_start_with_margin = pos_start - 0.025*total_length\n",
    "        for i, exon in enumerate(exons):\n",
    "            rectangle = plt.Rectangle(((exon[j] - pos_start_with_margin)/total_length_with_margin,offset), (exon[k] - exon[j])/total_length_with_margin, height, fc=color,ec=\"black\")\n",
    "            plt.gca().add_patch(rectangle)\n",
    "        if i > 0:\n",
    "            arrow = None\n",
    "            if direction < 0:\n",
    "                arrow = plt.arrow(1, offset - height/4, -1, 0, width=0.0015, head_length=0.01, head_width=0.1, length_includes_head=True, overhang=1)\n",
    "            else:\n",
    "                arrow = plt.arrow(0, offset - height/4, 1, 0, width=0.0015, head_length=0.01, head_width=0.1, length_includes_head=True, overhang=1)\n",
    "            plt.gca().add_patch(arrow)\n",
    "        plt.plot(np.array([0.025 + (real_start - pos_start) / (total_length)/1.05, 0.025 + (real_start - pos_start) / (total_length)/1.05]), np.array([offset - height/4 - 0.03, offset - height/4 + 0.03]), color='black')\n",
    "        plt.plot(np.array([1 - 0.025 - (pos_end - real_end) / (total_length)/1.05, 1 - 0.025 - (pos_end - real_end) / (total_length)/1.05]), np.array([offset - height/4 - 0.03, offset - height/4 + 0.03]), color='black')\n",
    "        plt.text(0.025 + (real_start - pos_start) / (total_length)/1.05, offset - height/4 - 0.075, real_start, horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "        plt.text(1 - 0.025 - (pos_end - real_end) / (total_length)/1.05, offset - height/4 - 0.075, real_end, horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "        plt.text(1, offset - height, transcript_name, horizontalalignment='right', verticalalignment='top', fontsize=12)\n",
    "        if not no_render:\n",
    "            plt.show()\n",
    "\n",
    "    def _draw_transcripts_list(self, trs_to_show, _ax, colors=None):\n",
    "        transcripts_id = trs_to_show\n",
    "        exons = []\n",
    "        directions = []\n",
    "        for tr in transcripts_id:\n",
    "            t, d = self._get_coord_from_tscrpt_id(tr)\n",
    "            exons += [t]\n",
    "            directions += [d]\n",
    "        if colors is None:\n",
    "            colors = []\n",
    "            for i in range(len(exons)):\n",
    "                colors.append(self.colors[i % len(self.colors)])\n",
    "        def get_limits(ex, dir):\n",
    "            start = sys.maxsize\n",
    "            end = -sys.maxsize\n",
    "            for (e, d) in zip(ex, dir):\n",
    "                if d == 1:\n",
    "                    start = min(start,e[0][1])\n",
    "                    end = max(end, e[-1][0])\n",
    "                else:\n",
    "                    start = min(start,e[-1][1])\n",
    "                    end = max(end, e[0][0])\n",
    "            return (start, end)\n",
    "        plt.axes()\n",
    "        plt.xlim((-0.1, 1.1))\n",
    "        plt.ylim((0.1 - 0.5 *  len(exons), 0.3))\n",
    "        plt.margins(0.2)\n",
    "        plt.axis('off')\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(20, len(exons) * 2)\n",
    "        i = 0\n",
    "        (start, end) = get_limits(exons, directions)\n",
    "        for (ex, di, co, name) in zip(exons, directions, colors, transcripts_id):\n",
    "            self._draw_transcript(ex, di, co, name, offset= -0.5 * i, start_override=start, end_override=end, no_render=True)\n",
    "            i+=1\n",
    "        if _ax is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            return plt\n",
    "\n",
    "    def draw_transcripts_list(self, transcripts_ids, colors=None):\n",
    "        self._draw_transcripts_list(transcripts_ids, None, colors)\n",
    "\n",
    "    def draw_transcripts_list_unscaled(self, transcripts_id, colors=None):\n",
    "        exons = []\n",
    "        directions = []\n",
    "        for tr in transcripts_id:\n",
    "            t, d = self._get_coord_from_tscrpt_id(tr)\n",
    "            exons += [t]\n",
    "            directions += [d]\n",
    "        if colors is None:\n",
    "            colors = []\n",
    "            for i in range(len(exons)):\n",
    "                colors.append(self.colors[i % len(self.colors)])\n",
    "        def get_limits(ex, dir):\n",
    "            start = sys.maxsize\n",
    "            end = -sys.maxsize\n",
    "            for (e, d) in zip(ex, dir):\n",
    "                if d == 1:\n",
    "                    start = min(start,e[0][1])\n",
    "                    end = max(end, e[-1][0])\n",
    "                else:\n",
    "                    start = min(start,e[-1][1])\n",
    "                    end = max(end, e[0][0])\n",
    "            return (start, end)\n",
    "\n",
    "        def move_exons(exons_list, direction, max_width, min_width):\n",
    "            i = 1\n",
    "            if direction == 1:\n",
    "                while i < len(exons_list):\n",
    "                    if exons_list[i][1] - exons_list[i - 1][0] < min_width:\n",
    "                        diff = min_width - (exons_list[i][1] - exons_list[i - 1][0])\n",
    "                        exons_list[i][0] += diff\n",
    "                        exons_list[i][1] += diff\n",
    "                    elif exons_list[i][1] - exons_list[i - 1][0] > max_width:\n",
    "                        diff = (exons_list[i][1] - exons_list[i - 1][0]) - max_width\n",
    "                        exons_list[i][0] -= diff\n",
    "                        exons_list[i][1] -= diff\n",
    "                    i += 1\n",
    "            else:\n",
    "                while i < len(exons_list):\n",
    "                    if exons_list[i][0] - exons_list[i - 1][1] < min_width:\n",
    "                        diff = min_width - (exons_list[i][0] - exons_list[i - 1][1])\n",
    "                        exons_list[i][1] += diff\n",
    "                        exons_list[i][0] += diff\n",
    "                    elif exons_list[i][0] - exons_list[i - 1][1] > max_width:\n",
    "                        diff = (exons_list[i][0] - exons_list[i - 1][1]) - max_width\n",
    "                        exons_list[i][1] -= diff\n",
    "                        exons_list[i][0] -= diff\n",
    "                    i += 1\n",
    "            return exons_list\n",
    "        plt.axes()\n",
    "        plt.xlim((-0.1, 1.1))\n",
    "        plt.ylim((0.1 - 0.5 *  len(exons), 0.3))\n",
    "        plt.margins(0.2)\n",
    "        plt.axis('off')\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(20, len(exons) * 2)\n",
    "        i = 0\n",
    "        fake_exons = []\n",
    "        fake_se = []\n",
    "        for exon_list, direction in zip(exons, directions):\n",
    "            fake_exon = []\n",
    "            (start, end) = get_limits([exon_list], [direction])\n",
    "            full_length = end - start\n",
    "            max_width = full_length / (len(exon_list) - 2 if len(exon_list) > 2 else 1)\n",
    "            min_width = full_length / (10 * (len(exon_list) + 5))\n",
    "            max_width_e = full_length / 2\n",
    "            min_width_e = full_length / 20\n",
    "            for exon in exon_list:\n",
    "                fake_exon_start = 0\n",
    "                fake_exon_end = 0\n",
    "                if direction == 1:\n",
    "                    fake_exon_start = exon[1]\n",
    "                    if (exon[0] - exon[1]) > max_width:\n",
    "                        fake_exon_end = exon[1] + max_width\n",
    "                    elif (exon[0] - exon[1]) < min_width:\n",
    "                        fake_exon_end = exon[1] + min_width\n",
    "                    else:\n",
    "                        fake_exon_end = exon[0]\n",
    "                    fake_exon.append([fake_exon_end, fake_exon_start])\n",
    "                else:\n",
    "                    fake_exon_start = exon[0]\n",
    "                    if (exon[1] - exon[0]) > max_width:\n",
    "                        fake_exon_end = exon[0] + max_width\n",
    "                    elif (exon[1] - exon[0]) < min_width:\n",
    "                        fake_exon_end = exon[0] + min_width\n",
    "                    else:\n",
    "                        fake_exon_end = exon[1]\n",
    "                    fake_exon.append([fake_exon_start, fake_exon_end])\n",
    "            fake_exon = move_exons(fake_exon, direction, max_width_e, min_width_e)\n",
    "            fake_exons.append(fake_exon)\n",
    "            (fake_s, fake_e) = get_limits([fake_exon], [direction])\n",
    "            fake_se.append([fake_s, fake_e])\n",
    "        for (ex, di, co, name) in zip(fake_exons, directions, colors, transcripts_id):\n",
    "            self._draw_transcript(ex, di, co, name, offset= -0.5 * i, start_override=fake_se[i][0], end_override=fake_se[i][1], no_render=True)\n",
    "            i+=1\n",
    "        plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
