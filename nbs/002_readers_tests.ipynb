{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa98b33e0036b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc8485e6a8715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp readers_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import sys\n",
    "import patchworklib as pw\n",
    "import urllib\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gammaln\n",
    "from scipy.optimize import minimize\n",
    "from itertools import combinations\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "from functools import lru_cache\n",
    "import pyranges as pr\n",
    "from pyfaidx import Fasta\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d693233b5eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import scanpy as sc\n",
    "import warnings\n",
    "import anndata as ad\n",
    "from anndata import AnnData\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "from functools import partial\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "def download_test_data(url: str = \"https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3748nnn/GSM3748087/suppl/GSM3748087%5F190c.isoforms.matrix.txt.gz\") -> str:\n",
    "    \"\"\"\n",
    "    Downloads a test data file from a specified URL, saves it locally, and extracts it.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL of the file to be downloaded. Defaults to a pre-defined test dataset.\n",
    "\n",
    "    Returns:\n",
    "    str: The absolute path of the extracted file if the download is successful, or None if it fails.\n",
    "    \"\"\"\n",
    "    print(f\"Starting download of test data from {url}\")\n",
    "\n",
    "    # Extract filename from the URL\n",
    "    filename = url.split('/')[-1]\n",
    "    compressed_file = filename\n",
    "\n",
    "    # Generate a unique filename for the extracted file\n",
    "    base_extracted_file = \"sample_isomatrix\"\n",
    "    counter = 1\n",
    "    extracted_file = f\"{base_extracted_file}.txt\"\n",
    "    while os.path.exists(extracted_file):\n",
    "        extracted_file = f\"{base_extracted_file}_{counter}.txt\"\n",
    "        counter += 1\n",
    "\n",
    "    # Download the file from the given URL\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, compressed_file)\n",
    "        print(\"File downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download the file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Extract the file\n",
    "    try:\n",
    "        with gzip.open(compressed_file, 'rb') as f_in:\n",
    "            with open(extracted_file, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        print(\"File extracted successfully\")\n",
    "        return os.path.abspath(extracted_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract the file: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        # Clean up the compressed file\n",
    "        if os.path.exists(compressed_file):\n",
    "            os.remove(compressed_file)\n",
    "\n",
    "#| export\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "\n",
    "def iso_concat(data_inputs, batch_info=None, batch_type='path'):\n",
    "    \"\"\"\n",
    "    Concatenates a list of AnnData objects or paths to AnnData objects based on the union of transcriptIds,\n",
    "    while preserving geneId information which might be non-unique per transcriptId.\n",
    "    Missing values are filled with zeros. Adds a batch column to `.obs` based on the file path, obs_names, or numeric.\n",
    "\n",
    "    Parameters:\n",
    "    data_inputs (list of str or AnnData):\n",
    "        List of paths to AnnData objects or AnnData objects to concatenate.\n",
    "    batch_info (list of str, optional):\n",
    "        List of batch identifiers for each AnnData object in data_inputs.\n",
    "        If not provided, batch identifiers are extracted from file paths, obs_names, or a numeric sequence.\n",
    "    batch_type (str, optional):\n",
    "        Specifies which type of batch information to use. One of ['path', 'obs_names', 'numeric'].\n",
    "        Defaults to 'path'.\n",
    "\n",
    "    Returns:\n",
    "    AnnData:\n",
    "        A single concatenated AnnData object with harmonized features, geneId annotations, and batch info.\n",
    "    \"\"\"\n",
    "    adata_list = []\n",
    "    df_list = []\n",
    "    gene_ids = {}\n",
    "    batch_info_list = []\n",
    "\n",
    "    for i, data_input in enumerate(data_inputs):\n",
    "        # Check if the input is a path (string) or an AnnData object\n",
    "        if isinstance(data_input, str):\n",
    "            adata = sc.read_h5ad(data_input)\n",
    "            # Determine batch label based on batch_type\n",
    "            if batch_type == 'path':\n",
    "                batch = os.path.basename(data_input).split('_isomatrix')[0] if batch_info is None else batch_info[i]\n",
    "            elif batch_type == 'obs_names':\n",
    "                batch = adata.obs_names[0] if batch_info is None else batch_info[i]\n",
    "            elif batch_type == 'numeric':\n",
    "                batch = str(i)\n",
    "            else:\n",
    "                raise ValueError(\"batch_type should be 'path', 'obs_names' or 'numeric'.\")\n",
    "        elif isinstance(data_input, AnnData):\n",
    "            adata = data_input\n",
    "            # Determine batch label when input is already an AnnData object\n",
    "            if batch_type == 'obs_names':\n",
    "                batch = adata.obs_names[0] if batch_info is None else batch_info[i]\n",
    "            elif batch_type == 'numeric':\n",
    "                batch = str(i)\n",
    "            else:\n",
    "                raise ValueError(\"batch_type should be 'obs_names' or 'numeric' when passing AnnData objects.\")\n",
    "        else:\n",
    "            raise ValueError(\"data_inputs must be a list of paths to AnnData objects or AnnData objects.\")\n",
    "\n",
    "        adata_list.append(adata)\n",
    "        # Convert adata.X to a DataFrame for outer-join concatenation\n",
    "        df = pd.DataFrame(adata.X.T, index=adata.var['transcriptId'], columns=adata.obs_names)\n",
    "        df_list.append(df)\n",
    "        batch_info_list.extend([batch] * adata.n_obs)\n",
    "\n",
    "        # Map transcriptId to its geneId\n",
    "        for transcript_id, gene_id in zip(adata.var['transcriptId'], adata.var['geneId']):\n",
    "            gene_ids[transcript_id] = gene_id\n",
    "\n",
    "    # Perform an outer join on all DataFrames\n",
    "    concat_df = pd.concat(df_list, axis=1, join='outer').fillna(0)\n",
    "\n",
    "    # Create a new var DataFrame with geneIds mapped from transcriptIds\n",
    "    var_df = pd.DataFrame(index=concat_df.index)\n",
    "    var_df['geneId'] = pd.Series(gene_ids).reindex(concat_df.index)\n",
    "\n",
    "    # Build an AnnData object, transposing so obs are rows\n",
    "    concatenated_adata = sc.AnnData(X=concat_df.T, var=var_df)\n",
    "\n",
    "    # Add batch info to obs\n",
    "    concatenated_adata.obs['batch'] = batch_info_list\n",
    "\n",
    "    return concatenated_adata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5425abdee359fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy.sparse import csr_matrix\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "\n",
    "def read_sicelore_isomatrix(\n",
    "    file_path: str,\n",
    "    gene_id_label: str = \"geneId\",\n",
    "    transcript_id_label: str = \"transcriptId\",\n",
    "    remove_undef: bool = True,\n",
    "    sparse: bool = False\n",
    ") -> AnnData:\n",
    "    \"\"\"\n",
    "    Read a SiCeLoRe isomatrix file (tab-delimited) and convert it into a scanpy-compatible AnnData object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to the isomatrix file (tab-delimited).\n",
    "    gene_id_label : str, optional\n",
    "        Row/column label used for gene IDs (default \"geneId\").\n",
    "    transcript_id_label : str, optional\n",
    "        Row/column label used for transcript IDs (default \"transcriptId\").\n",
    "    remove_undef : bool, optional\n",
    "        Whether to remove rows with transcriptId=\"undef\" (default True).\n",
    "    sparse : bool, optional\n",
    "        Whether to store the matrix in sparse format (default False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    anndata.AnnData\n",
    "        An AnnData object containing numeric data in `.X` and metadata in `.var`.\n",
    "    \"\"\"\n",
    "    # Read in the file, expecting rows to be features initially\n",
    "    df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "    # Optionally remove rows marked as \"undef\" in the transcript column\n",
    "    if remove_undef and (transcript_id_label in df.columns):\n",
    "        df = df[df[transcript_id_label] != \"undef\"]\n",
    "\n",
    "    # Reset and transpose so columns become features (var) and rows become observations (obs)\n",
    "    df = df.reset_index()\n",
    "    df = df.transpose()\n",
    "\n",
    "    # Identify potential metadata rows (e.g., geneId, transcriptId, nbExons)\n",
    "    known_metadata_labels = [gene_id_label, transcript_id_label]\n",
    "    metadata_rows = [idx for idx in df.index if idx in known_metadata_labels or \"Exons\" in idx]\n",
    "\n",
    "    # Extract metadata if present\n",
    "    metadata_df = df.loc[metadata_rows] if metadata_rows else pd.DataFrame()\n",
    "    # Drop them from the numeric data\n",
    "    df = df.drop(metadata_rows, errors='ignore')\n",
    "\n",
    "    # Convert to float and optionally to a sparse matrix\n",
    "    try:\n",
    "        numeric_data = df.values.astype('float32')\n",
    "    except ValueError:\n",
    "        print(\"Error: Non-numeric data present in the DataFrame. Cannot convert to float.\")\n",
    "        return None\n",
    "\n",
    "    if sparse:\n",
    "        numeric_data = csr_matrix(numeric_data)\n",
    "\n",
    "    # Create AnnData object\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        adata = sc.AnnData(\n",
    "            X=numeric_data,\n",
    "            obs=pd.DataFrame(index=df.index.astype(str)),\n",
    "            var=pd.DataFrame(index=df.columns.astype(str))\n",
    "        )\n",
    "\n",
    "    # Attach metadata to the AnnData var\n",
    "    if not metadata_df.empty:\n",
    "        for row_label in metadata_df.index.unique():\n",
    "            adata.var[row_label] = metadata_df.loc[row_label].astype(str).values\n",
    "\n",
    "    # Make observation names unique\n",
    "    adata.obs_names_make_unique()\n",
    "\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249c6250c040eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    df = pd.read_csv('/data/analysis/data_mcandrew/e18.mouse.clusters.csv')\n",
    "    df['barcode'] = df.index.str.split('_').str[1]\n",
    "\n",
    "\n",
    "    mouse_data_str_1 = download_test_data()\n",
    "    print(\"Test data downloaded successfully\")\n",
    "\n",
    "\n",
    "    mouse_data_str_2 = download_test_data(\"https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3748nnn/GSM3748089/suppl/GSM3748089%5F951c.isoforms.matrix.txt.gz\")\n",
    "    print(\"Test data downloaded successfully\")\n",
    "\n",
    "\n",
    "    mouse_1 = read_sicelore_isomatrix(file_path=mouse_data_str_1)\n",
    "    mouse_2 = read_sicelore_isomatrix(file_path=mouse_data_str_2)\n",
    "\n",
    "    combined_mouse_data = iso_concat([mouse_1, mouse_2], batch_type='numeric')\n",
    "\n",
    "\n",
    "    combined_mouse_data.obs_names_make_unique()\n",
    "    # Step 1: Remove any duplicate barcodes in the DataFrame\n",
    "    df_unique = df.drop_duplicates(subset='barcode')\n",
    "\n",
    "    # Step 2: Filter the DataFrame to include only the barcodes present in the AnnData object\n",
    "    df_filtered = df_unique[df_unique['barcode'].isin(combined_mouse_data.obs_names)]\n",
    "\n",
    "    # Step 3: Set the index of the filtered DataFrame to 'barcode' to make the merge easier\n",
    "    df_filtered.set_index('barcode', inplace=True)\n",
    "\n",
    "    # Step 4: Create a DataFrame from the obs DataFrame of the AnnData object to ensure the same index\n",
    "    obs_df = combined_mouse_data.obs.copy()\n",
    "\n",
    "    # Step 5: Initialize a new column 'cell_type' with NaN values in the obs DataFrame\n",
    "    obs_df['cell_type'] = pd.NA\n",
    "\n",
    "    # Step 6: Update the 'cell_type' column with values from the filtered DataFrame where indices match\n",
    "    obs_df.update(df_filtered['illumina.ident'].rename('cell_type'))\n",
    "\n",
    "    # Step 7: Ensure the index is unique and assign the updated DataFrame back to the obs attribute of the AnnData object\n",
    "    if obs_df.index.is_unique:\n",
    "        combined_mouse_data.obs = obs_df\n",
    "    else:\n",
    "        raise ValueError(\"The index of the obs DataFrame is not unique.\")\n",
    "\n",
    "    # Now, the 'cell_type' column should be added to the obs DataFrame of your AnnData object\n",
    "    combined_mouse_data = combined_mouse_data[~combined_mouse_data.obs['cell_type'].isna()]\n",
    "    combined_mouse_data.var\n",
    "    sc.pp.filter_genes(combined_mouse_data, min_cells=1)\n",
    "    sc.pp.filter_cells(combined_mouse_data, min_genes=1)\n",
    "    sc.pp.normalize_total(combined_mouse_data, target_sum=1e6)\n",
    "    sc.pp.log1p(combined_mouse_data)\n",
    "    sc.pp.neighbors(combined_mouse_data)\n",
    "    sc.tl.umap(combined_mouse_data)\n",
    "    sc.pl.umap(combined_mouse_data)\n",
    "    sc.pl.umap(combined_mouse_data,color = \"cell_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce4199ee3dcfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc70d4e1ba26b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37a8f073bb1089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7823c3a51abf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a0210500750482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
