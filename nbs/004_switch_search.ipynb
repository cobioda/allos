{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179f3cd8114dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa090e541302e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp switch_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allos.anndata_iso'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultitest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multipletests\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mallos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manndata_iso\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnDataIso\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allos.anndata_iso'"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import sys\n",
    "import patchworklib as pw\n",
    "import urllib\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gammaln\n",
    "from scipy.optimize import minimize\n",
    "from itertools import combinations\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "from functools import lru_cache\n",
    "import pyranges as pr\n",
    "from pyfaidx import Fasta\n",
    "import logging\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from allos.anndata_iso import AnnDataIso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319a1177ddfc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.special import gammaln\n",
    "from scipy.optimize import minimize\n",
    "from itertools import combinations\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import scanpy as sc\n",
    "import requests\n",
    "\n",
    "###############################################################################\n",
    "# Helper functions for Dirichlet-Multinomial Negative Log-Likelihood + MLE\n",
    "###############################################################################\n",
    "def _dirichlet_multinomial_nll(alpha, data_np):\n",
    "    \"\"\"\n",
    "    Compute the negative log-likelihood for a Dirichlet-Multinomial model,\n",
    "    given 'data_np' (shape M x K) and 'alpha' (shape K, > 0).\n",
    "    Omits the factorial terms that don't depend on alpha.\n",
    "    \"\"\"\n",
    "    if np.any(alpha <= 0):\n",
    "        return np.inf\n",
    "\n",
    "    alpha_sum = np.sum(alpha)\n",
    "    nll = 0.0\n",
    "    for row in data_np:\n",
    "        N = np.sum(row)\n",
    "        # part that depends on alpha_sum\n",
    "        nll -= gammaln(alpha_sum)\n",
    "        nll += gammaln(alpha_sum + N)\n",
    "        # part that depends on alpha_j\n",
    "        for j in range(len(alpha)):\n",
    "            nll -= gammaln(alpha[j] + row[j]) - gammaln(alpha[j])\n",
    "    return float(nll)\n",
    "\n",
    "def _dm_mle(data):\n",
    "    \"\"\"\n",
    "    SciPy-based Dirichlet-Multinomial MLE on a NumPy array.\n",
    "    data: shape (M, K)\n",
    "    Returns: (nll, alpha_hat)\n",
    "    \"\"\"\n",
    "    K = data.shape[1]\n",
    "\n",
    "    def objective(alpha):\n",
    "        return _dirichlet_multinomial_nll(alpha, data)\n",
    "\n",
    "    init_alpha = np.ones(K) + 0.1\n",
    "    bounds = [(1e-9, None)] * K\n",
    "\n",
    "    result = minimize(\n",
    "        fun=objective,\n",
    "        x0=init_alpha,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds,\n",
    "        options={'maxiter': 10000, 'ftol': 1e-5}\n",
    "    )\n",
    "    if not result.success:\n",
    "        return float('nan'), np.zeros(K)\n",
    "\n",
    "    return float(result.fun), result.x\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Example placeholder for a scattermap function (if you have your own, remove this)\n",
    "###############################################################################\n",
    "def scattermap(color_data, marker_size=None, square=True, cmap=\"Reds\",\n",
    "               cbar_kws=None, xticklabels=None, yticklabels=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Minimal example of a \"scattermap\" function that draws circles whose\n",
    "    color indicates one value and size indicates another. You likely have\n",
    "    your own version. Adjust as needed, or remove if you define it elsewhere.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    n_rows = color_data.shape[0]\n",
    "    n_cols = color_data.shape[1]\n",
    "\n",
    "    if marker_size is None:\n",
    "        marker_size = np.ones_like(color_data)*20.0\n",
    "\n",
    "    # Plot each cell as a circle in a grid.\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            # x is column index, y is row index\n",
    "            circle_color = color_data[i, j]\n",
    "            circle_size = marker_size[i, j]*5  # scale up\n",
    "            sc = ax.scatter(j, i, s=circle_size, c=circle_color,\n",
    "                            cmap=cmap, vmin=color_data.min(), vmax=color_data.max())\n",
    "    # Ticks\n",
    "    ax.set_xticks(range(n_cols))\n",
    "    ax.set_yticks(range(n_rows))\n",
    "    if xticklabels is not None:\n",
    "        ax.set_xticklabels(xticklabels, rotation=90)\n",
    "    if yticklabels is not None:\n",
    "        ax.set_yticklabels(yticklabels)\n",
    "    if cbar_kws is None:\n",
    "        cbar_kws = {}\n",
    "    plt.colorbar(sc, ax=ax, **cbar_kws)\n",
    "    if square:\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "    return ax\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# The SwitchSearch class\n",
    "###############################################################################\n",
    "class SwitchSearch(sc.AnnData):\n",
    "    \"\"\"\n",
    "    An AnnData subclass with specialized Dirichlet-based and Wilcoxon-based\n",
    "    isoform 'switch' detection methods, plus helper plots and caches.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, anndata, cell_types=None):\n",
    "        \"\"\"\n",
    "        anndata: A scanpy.AnnData object\n",
    "        cell_types: Pandas Series or list of cell-type labels (optional)\n",
    "        \"\"\"\n",
    "        super().__init__(anndata.X, obs=anndata.obs.copy(),\n",
    "                         var=anndata.var.copy(), uns=anndata.uns.copy(),\n",
    "                         obsm=anndata.obsm.copy(), varm=anndata.varm.copy(),\n",
    "                         layers=anndata.layers.copy())\n",
    "\n",
    "        # Basic coloring scheme (feel free to adjust)\n",
    "        self.colors = [\"#BF045B\", \"#038C33\", \"#73BF86\", \"#D9B29C\", \"#A65F46\",\n",
    "                       \"#D9C252\", \"#F2BF91\", \"#A69C94\", \"#D9763D\", \"#8C2F1B\"]\n",
    "        self.relevant_genes = None\n",
    "\n",
    "        # Caches for Dirichlet single-group and combined fits\n",
    "        self._single_fit_cache = {}    # (group_label, gene_id) -> (nll, alpha)\n",
    "        self._combined_fit_cache = {}  # (group1, group2, gene_id) -> (nll, alpha)\n",
    "\n",
    "        # Add cell_type column if provided\n",
    "        if cell_types is not None:\n",
    "            self.obs['cell_type'] = cell_types\n",
    "        elif 'cell_type' not in self.obs.columns:\n",
    "            # If you want a fallback\n",
    "            self.obs['cell_type'] = \"Unknown\"\n",
    "\n",
    "        # Keep track of multi-isoform filtering\n",
    "        self.__filtered_anndata = self.__filter_isodata()\n",
    "\n",
    "        # Just to keep track of gene/transcript counts\n",
    "        # We'll do a quick groupby on var\n",
    "        df_count = self.var.reset_index().groupby('geneId').count()\n",
    "        if 'transcriptId' not in df_count.columns:\n",
    "            # If user didn't have transcriptId, set them\n",
    "            self.var['transcriptId'] = self.var_names\n",
    "            df_count = self.var.reset_index().groupby('geneId').count()\n",
    "        self.gene_counts = df_count\n",
    "\n",
    "        # Precompute isoform percentage matrix in .obsm, if desired\n",
    "        df = self.__filtered_anndata.to_df().set_index(self.__filtered_anndata.obs.index)\n",
    "        df_t = df.transpose()\n",
    "        df_t[['transcriptId', 'geneId']] = self.__filtered_anndata.var[['transcriptId', 'geneId']]\n",
    "        df_m_iso = self.iso_percent(df_t)\n",
    "        # Drop the last 2 columns (transcriptId, geneId) after iso_percent\n",
    "        df_m_iso = df_m_iso.iloc[:, :-2].transpose()\n",
    "        self.__filtered_anndata.obsm['Iso_prct'] = df_m_iso\n",
    "\n",
    "    ###########################################################################\n",
    "    # Internal: filter raw data to multi-isoform genes\n",
    "    ###########################################################################\n",
    "    def __filter_isodata(self):\n",
    "        \"\"\"\n",
    "        Returns a copy of self restricted to genes that have >1 isoform\n",
    "        (based on 'geneId' in self.var).\n",
    "        \"\"\"\n",
    "        if 'geneId' not in self.var.columns:\n",
    "            # We can't filter\n",
    "            return self.copy()\n",
    "\n",
    "        genes, freq = np.unique(self.var['geneId'], return_counts=True)\n",
    "        df = pd.DataFrame({\"geneId\": genes, \"frequencies\": freq})\n",
    "        multi_iso_genes = df[df[\"frequencies\"] > 1]['geneId'].tolist()\n",
    "\n",
    "        adata_iso = self[:, self.var['geneId'].isin(multi_iso_genes)].copy()\n",
    "        return adata_iso\n",
    "\n",
    "    ###########################################################################\n",
    "    # Internal: compute iso percentages\n",
    "    ###########################################################################\n",
    "    def iso_percent(self, df, barcodes_regex=\"^[ACGT]+$\"):\n",
    "        \"\"\"\n",
    "        Given a df with each isoform in rows, cell barcodes in columns,\n",
    "        sum counts per gene, then convert to fraction of total for that gene.\n",
    "        'barcodes_regex' identifies which columns are actual cells.\n",
    "        \"\"\"\n",
    "        iso_perc_df = df.copy(deep=True)\n",
    "\n",
    "        # Identify the columns that match 'barcodes_regex' (your usage may vary)\n",
    "        # For demonstration, let's just assume every column except geneId/transcriptId is a \"barcode\"\n",
    "        # or do a more custom approach if needed.\n",
    "        if len(iso_perc_df.filter(regex=(barcodes_regex)).columns) < 1:\n",
    "            raise ValueError(\"No cell-barcode columns were identified. Check 'barcodes_regex' or your column naming.\")\n",
    "\n",
    "        # For each gene, sum across columns -> transform\n",
    "        cols_barcodes = iso_perc_df.filter(regex=(barcodes_regex)).columns\n",
    "        gene_sums = iso_perc_df.groupby(['geneId'])[cols_barcodes].transform('sum')\n",
    "        iso_perc_df[cols_barcodes] = iso_perc_df[cols_barcodes] / gene_sums\n",
    "        iso_perc_df.replace(np.nan, 0.0, inplace=True)\n",
    "\n",
    "        return iso_perc_df\n",
    "\n",
    "    ###########################################################################\n",
    "    # Dirichlet-based single-group / combined fits, with caching\n",
    "    ###########################################################################\n",
    "    def __fit_single_group(self, group_label, gene_id, cell_group_column='cell_type'):\n",
    "        \"\"\"\n",
    "        Returns (nll, alpha) for a single group's data on a given gene,\n",
    "        filtered to rows with sum > 9. Uses and updates self._single_fit_cache.\n",
    "        If no data remains, returns (np.nan, None).\n",
    "        \"\"\"\n",
    "        cache_key = (group_label, gene_id)\n",
    "        if cache_key in self._single_fit_cache:\n",
    "            return self._single_fit_cache[cache_key]\n",
    "\n",
    "        group_data = self[self.obs[cell_group_column] == group_label]\n",
    "        if 'geneId' not in group_data.var.columns:\n",
    "            return (np.nan, None)\n",
    "\n",
    "        mask_gene = (group_data.var['geneId'] == gene_id)\n",
    "        data = group_data[:, mask_gene].X.toarray()\n",
    "        total_counts = data.sum(axis=1)\n",
    "        data = data[total_counts > 9]\n",
    "\n",
    "        if data.shape[0] == 0:\n",
    "            self._single_fit_cache[cache_key] = (np.nan, None)\n",
    "            return (np.nan, None)\n",
    "\n",
    "        nll, alpha = _dm_mle(data)\n",
    "        self._single_fit_cache[cache_key] = (nll, alpha)\n",
    "        return (nll, alpha)\n",
    "\n",
    "    def __fit_combined(self, group_label1, group_label2, gene_id, cell_group_column='cell_type'):\n",
    "        \"\"\"\n",
    "        Returns (nll, alpha) for combined data from group_label1 + group_label2 on a gene,\n",
    "        filtered to rows with sum > 9. Caches results. If no data remains, returns (np.nan, None).\n",
    "        \"\"\"\n",
    "        cache_key = (group_label1, group_label2, gene_id)\n",
    "        if cache_key in self._combined_fit_cache:\n",
    "            return self._combined_fit_cache[cache_key]\n",
    "\n",
    "        # group1\n",
    "        group1 = self[self.obs[cell_group_column] == group_label1]\n",
    "        if 'geneId' not in group1.var.columns:\n",
    "            self._combined_fit_cache[cache_key] = (np.nan, None)\n",
    "            return (np.nan, None)\n",
    "\n",
    "        mask1 = (group1.var['geneId'] == gene_id)\n",
    "        data1 = group1[:, mask1].X.toarray()\n",
    "        total_counts1 = data1.sum(axis=1)\n",
    "        data1 = data1[total_counts1 > 9]\n",
    "\n",
    "        # group2\n",
    "        group2 = self[self.obs[cell_group_column] == group_label2]\n",
    "        if 'geneId' not in group2.var.columns:\n",
    "            self._combined_fit_cache[cache_key] = (np.nan, None)\n",
    "            return (np.nan, None)\n",
    "\n",
    "        mask2 = (group2.var['geneId'] == gene_id)\n",
    "        data2 = group2[:, mask2].X.toarray()\n",
    "        total_counts2 = data2.sum(axis=1)\n",
    "        data2 = data2[total_counts2 > 9]\n",
    "\n",
    "        # Combined\n",
    "        if data1.shape[0] == 0 or data2.shape[0] == 0:\n",
    "            self._combined_fit_cache[cache_key] = (np.nan, None)\n",
    "            return (np.nan, None)\n",
    "\n",
    "        combined_data = np.vstack([data1, data2])\n",
    "        nll, alpha = _dm_mle(combined_data)\n",
    "        self._combined_fit_cache[cache_key] = (nll, alpha)\n",
    "        return (nll, alpha)\n",
    "\n",
    "    def __cached_LRT_test(self, group_label1, group_label2, gene_id, cell_group_column='cell_type'):\n",
    "        \"\"\"\n",
    "        Performs the LRT: 2*(nll_full - (nll1 + nll2)) ~ Chi2(K).\n",
    "        Uses cached single-group and combined fits. Returns None if something fails.\n",
    "        Otherwise returns (chi2_stat, p_value, alpha_full, alpha1, alpha2).\n",
    "        \"\"\"\n",
    "        loss1, alpha1 = self.__fit_single_group(group_label1, gene_id, cell_group_column)\n",
    "        loss2, alpha2 = self.__fit_single_group(group_label2, gene_id, cell_group_column)\n",
    "        if alpha1 is None or alpha2 is None or np.isnan(loss1) or np.isnan(loss2):\n",
    "            return None\n",
    "\n",
    "        loss_full, alpha_full = self.__fit_combined(group_label1, group_label2, gene_id, cell_group_column)\n",
    "        if alpha_full is None or np.isnan(loss_full):\n",
    "            return None\n",
    "\n",
    "        chi2_stat = 2.0 * (loss_full - (loss1 + loss2))\n",
    "        if chi2_stat < 0:\n",
    "            return None\n",
    "\n",
    "        K = len(alpha_full)  # degrees of freedom\n",
    "        p_value = 1.0 - chi2.cdf(chi2_stat, df=K)\n",
    "        return chi2_stat, p_value, alpha_full, alpha1, alpha2\n",
    "\n",
    "    def __compare_groups(self, group_1_label, group_2_label, cell_group_column, gene_id):\n",
    "        \"\"\"\n",
    "        Return a dict with 'chi2_stat', 'p_value', 'alpha_*' for the two groups + combined,\n",
    "        plus transcript_ids, or None if no test was done.\n",
    "        \"\"\"\n",
    "        test_result = self.__cached_LRT_test(group_1_label, group_2_label, gene_id, cell_group_column)\n",
    "        if test_result is None:\n",
    "            return None\n",
    "        chi2_stat, p_value, alpha_combined, alpha1, alpha2 = test_result\n",
    "\n",
    "        # gather the transcripts associated with that gene\n",
    "        transcripts = self.var_names[self.var['geneId'] == gene_id].tolist()\n",
    "        return {\n",
    "            \"chi2_stat\": chi2_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"alpha_combined\": alpha_combined.tolist(),\n",
    "            \"alpha1\": alpha1.tolist(),\n",
    "            \"alpha2\": alpha2.tolist(),\n",
    "            \"transcript_ids\": transcripts\n",
    "        }\n",
    "\n",
    "    def __filter_genes(self, group_1_label, group_2_label, cell_group_column,\n",
    "                       min_count=9, min_diff=0.1):\n",
    "        \"\"\"\n",
    "        Restrict to genes present in both groups at min_count, and\n",
    "        that differ in overall transcript usage by at least min_diff.\n",
    "        Returns a new SwitchSearch containing the filtered data.\n",
    "        \"\"\"\n",
    "        group_1 = self[self.obs[cell_group_column] == group_1_label]\n",
    "        group_2 = self[self.obs[cell_group_column] == group_2_label]\n",
    "\n",
    "        gene_counts_1 = np.array(group_1.X.sum(axis=0)).flatten()\n",
    "        gene_counts_2 = np.array(group_2.X.sum(axis=0)).flatten()\n",
    "        total_gene_counts = gene_counts_1 + gene_counts_2\n",
    "\n",
    "        # Genes passing total read threshold\n",
    "        valid_genes_mask = total_gene_counts > min_count\n",
    "        adata_slice = self[:, valid_genes_mask]\n",
    "\n",
    "        # Now each group's slice\n",
    "        group_1_slice = adata_slice[adata_slice.obs[cell_group_column] == group_1_label]\n",
    "        group_2_slice = adata_slice[adata_slice.obs[cell_group_column] == group_2_label]\n",
    "\n",
    "        nz1 = (group_1_slice.X != 0).sum(axis=0) > min_count\n",
    "        nz2 = (group_2_slice.X != 0).sum(axis=0) > min_count\n",
    "        final_valid_genes = nz1 & nz2\n",
    "\n",
    "        filtered_data = adata_slice[:, final_valid_genes]\n",
    "\n",
    "        # Additional pass to exclude genes whose transcripts do not differ by > min_diff in usage\n",
    "        unique_gene_ids = np.unique(filtered_data.var['geneId'])\n",
    "        for gene_id in unique_gene_ids:\n",
    "            sub1 = filtered_data[(filtered_data.obs[cell_group_column] == group_1_label),\n",
    "                                 (filtered_data.var['geneId'] == gene_id)]\n",
    "            sub2 = filtered_data[(filtered_data.obs[cell_group_column] == group_2_label),\n",
    "                                 (filtered_data.var['geneId'] == gene_id)]\n",
    "            X1 = sub1.X.astype(float).toarray()\n",
    "            X2 = sub2.X.astype(float).toarray()\n",
    "            if X1.sum() == 0 or X2.sum() == 0:\n",
    "                # remove this gene entirely\n",
    "                filtered_data = filtered_data[:, filtered_data.var['geneId'] != gene_id]\n",
    "                continue\n",
    "            percent_1 = X1 / X1.sum()\n",
    "            percent_2 = X2 / X2.sum()\n",
    "            diff_found = False\n",
    "            for col_idx in range(percent_1.shape[1]):\n",
    "                if abs(percent_1[:, col_idx].sum() - percent_2[:, col_idx].sum()) > min_diff:\n",
    "                    diff_found = True\n",
    "                    break\n",
    "            if not diff_found:\n",
    "                filtered_data = filtered_data[:, filtered_data.var['geneId'] != gene_id]\n",
    "\n",
    "        return SwitchSearch(filtered_data)\n",
    "\n",
    "    ###########################################################################\n",
    "    # Wilcoxon-based approach using Scanpy\n",
    "    ###########################################################################\n",
    "    def __scanpy_wilcoxon_switching_isoforms(self, cell_labels_column='cell_type',\n",
    "                                             min_fdr=0.05, min_log_fold_change=0.3):\n",
    "        \"\"\"\n",
    "        Uses Scanpy's rank_genes_groups (Wilcoxon) to find transcripts that\n",
    "        significantly differ between pairs of cell types. We then filter for\n",
    "        changes in usage. Returns a DataFrame of results.\n",
    "        \"\"\"\n",
    "        # Work on a copy to avoid side effects\n",
    "        adata = self.copy()\n",
    "\n",
    "        if adata.shape[0] == 0:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Make sure 'transcriptId' is in var\n",
    "        if 'transcriptId' not in adata.var.columns:\n",
    "            adata.var['transcriptId'] = adata.var_names\n",
    "\n",
    "        adata.obs[cell_labels_column] = adata.obs[cell_labels_column].astype('category')\n",
    "        groups = adata.obs[cell_labels_column].cat.categories\n",
    "        if len(groups) < 2:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # We'll do pairwise group tests in both directions\n",
    "        marker_results_list = {}\n",
    "        try:\n",
    "            from itertools import combinations\n",
    "            for g1, g2 in combinations(groups, 2):\n",
    "                # rank_genes_groups for g1 vs g2\n",
    "                sc.tl.rank_genes_groups(adata, groupby=cell_labels_column,\n",
    "                                        groups=[g1], reference=g2,\n",
    "                                        method='wilcoxon', n_genes=adata.shape[1])\n",
    "                df1 = sc.get.rank_genes_groups_df(adata, group=g1)\n",
    "                df1['group_1'] = g1\n",
    "                df1['group_2'] = g2\n",
    "                df1['contrast'] = f\"{g1}__{g2}\"\n",
    "\n",
    "                # rank_genes_groups for g2 vs g1\n",
    "                sc.tl.rank_genes_groups(adata, groupby=cell_labels_column,\n",
    "                                        groups=[g2], reference=g1,\n",
    "                                        method='wilcoxon', n_genes=adata.shape[1])\n",
    "                df2 = sc.get.rank_genes_groups_df(adata, group=g2)\n",
    "                df2['group_1'] = g2\n",
    "                df2['group_2'] = g1\n",
    "                df2['contrast'] = f\"{g1}__{g2}\"\n",
    "\n",
    "                if not df1.empty and not df2.empty:\n",
    "                    merged_key = df1['contrast'].iloc[0]\n",
    "                    marker_results_list[merged_key] = pd.concat([df1, df2], ignore_index=True)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        if not marker_results_list:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        marker_df = pd.concat(marker_results_list.values(), ignore_index=True)\n",
    "\n",
    "        # Map transcripts to genes\n",
    "        transcript_to_gene = adata.var.set_index('transcriptId')['geneId'].to_dict()\n",
    "        marker_df['geneId'] = marker_df['names'].map(transcript_to_gene)\n",
    "\n",
    "        # cell counts\n",
    "        cell_counts = adata.obs[cell_labels_column].value_counts()\n",
    "        marker_df['n_cells_group_1'] = marker_df['group_1'].map(cell_counts)\n",
    "        marker_df['n_cells_group_2'] = marker_df['group_2'].map(cell_counts)\n",
    "        marker_df['total_cells'] = marker_df['n_cells_group_1'] + marker_df['n_cells_group_2']\n",
    "\n",
    "        # Adjust p-values (FDR) & filter by log fold change\n",
    "        marker_df['adj_pval'] = multipletests(marker_df['pvals_adj'], method='fdr_bh')[1]\n",
    "        marker_df_filtered = marker_df[\n",
    "            (marker_df['adj_pval'] <= min_fdr) &\n",
    "            (marker_df['logfoldchanges'].abs() >= min_log_fold_change)\n",
    "        ]\n",
    "\n",
    "        # Add direction of fold change for each row\n",
    "        def assign_direction(local_df):\n",
    "            return local_df.assign(\n",
    "                direction=np.where(\n",
    "                    local_df['group_1'] == local_df['contrast'].str.split(\"__\").str[0],\n",
    "                    local_df['logfoldchanges'],\n",
    "                    -local_df['logfoldchanges']\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Keep only transcripts that differ in at least 2 directions or have multi usage\n",
    "        isoswitch_df = (\n",
    "            marker_df_filtered\n",
    "            .groupby(['geneId', 'contrast'])\n",
    "            .apply(assign_direction)\n",
    "            .reset_index(drop=True)\n",
    "            .groupby(['geneId', 'contrast'])\n",
    "            .filter(lambda x: (\n",
    "                len(x['group_1'].unique()) > 1 and\n",
    "                len(x['names'].unique()) > 1 and\n",
    "                x['direction'].abs().sum() != 0\n",
    "            ))\n",
    "        )\n",
    "\n",
    "        # Optionally compute percent-expression. Adjust if you prefer something else.\n",
    "        def calculate_percent_expression(_adata, grp_col, grp, transcript):\n",
    "            sub = _adata[_adata.obs[grp_col] == grp, transcript]\n",
    "            return (sub.X > 0).mean() * 100\n",
    "\n",
    "        per_expr = isoswitch_df.apply(\n",
    "            lambda row: pd.Series({\n",
    "                'percent_expressed_group_1': calculate_percent_expression(adata, cell_labels_column, row['group_1'], row['names']),\n",
    "                'percent_expressed_group_2': calculate_percent_expression(adata, cell_labels_column, row['group_2'], row['names']),\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "        isoswitch_df = pd.concat([isoswitch_df, per_expr], axis=1)\n",
    "        isoswitch_df.sort_values(by='adj_pval', inplace=True)\n",
    "\n",
    "        return isoswitch_df\n",
    "\n",
    "    ###########################################################################\n",
    "    # Public method: find_switching_isoforms\n",
    "    ###########################################################################\n",
    "    def find_switching_isoforms(self,\n",
    "                                cell_group_column='cell_type',\n",
    "                                min_count=30,\n",
    "                                min_diff=0.2,\n",
    "                                method=\"ScanpyWilcoxon\",\n",
    "                                min_fdr=0.05,\n",
    "                                min_log_fold_change=0.5):\n",
    "        \"\"\"\n",
    "        Finds switching isoforms. By default uses a Wilcoxon-based approach\n",
    "        (Scanpy's rank_genes_groups). If you want the original Dirichlet-based\n",
    "        approach, specify `method='Dirichlet'`.\n",
    "\n",
    "        For Dirichlet:\n",
    "            - min_count, min_diff apply\n",
    "        For Wilcoxon:\n",
    "            - min_fdr, min_log_fold_change apply\n",
    "\n",
    "        Returns a DataFrame of results, stored in self.relevant_genes (Dirichlet)\n",
    "        or returned directly (Wilcoxon).\n",
    "        \"\"\"\n",
    "        if method == \"Dirichlet\":\n",
    "            # Original approach: LRT\n",
    "            if 'geneId' not in self.var.columns:\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            cell_types = self.obs[cell_group_column].unique()\n",
    "            gene_ids = self.var['geneId'].unique()\n",
    "\n",
    "            results = []\n",
    "            for (g1, g2) in combinations(cell_types, 2):\n",
    "                # filter the data for these two groups\n",
    "                filtered_adata = self.__filter_genes(g1, g2, cell_group_column, min_count, min_diff)\n",
    "                # run a test on every gene in gene_ids\n",
    "                for gene_id in gene_ids:\n",
    "                    if gene_id not in filtered_adata.var['geneId'].values:\n",
    "                        continue\n",
    "                    item = filtered_adata.__compare_groups(g1, g2, cell_group_column, gene_id)\n",
    "                    if item is not None:\n",
    "                        results.append({\n",
    "                            'gene_id': gene_id,\n",
    "                            'group_1': g1,\n",
    "                            'group_2': g2,\n",
    "                            'p_value': item['p_value'],\n",
    "                            'chi2_stat': item['chi2_stat'],\n",
    "                            'alpha_combined': item['alpha_combined'],\n",
    "                            'alpha1': item['alpha1'],\n",
    "                            'alpha2': item['alpha2'],\n",
    "                            'transcript_ids': item['transcript_ids']\n",
    "                        })\n",
    "\n",
    "            # Store as DataFrame\n",
    "            results_df = pd.DataFrame(results)\n",
    "            self.relevant_genes = results_df\n",
    "            return results_df\n",
    "\n",
    "        else:\n",
    "            # New approach: Wilcoxon with Scanpy\n",
    "            isoswitch_df = self.__scanpy_wilcoxon_switching_isoforms(\n",
    "                cell_labels_column=cell_group_column,\n",
    "                min_fdr=min_fdr,\n",
    "                min_log_fold_change=min_log_fold_change\n",
    "            )\n",
    "            return isoswitch_df\n",
    "\n",
    "    ###########################################################################\n",
    "    # Major/Minor isoforms: simple method that looks at average usage\n",
    "    ###########################################################################\n",
    "    def __find_major_minor_isoforms(self):\n",
    "        \"\"\"\n",
    "        Example method returning the transcript IDs that are 'major' in\n",
    "        exactly one cell type. Adjust to your logic as needed.\n",
    "        \"\"\"\n",
    "        df = self.__filtered_anndata.to_df()\n",
    "        df['cell_type'] = self.__filtered_anndata.obs['cell_type']\n",
    "        df = df.groupby('cell_type').mean().transpose()\n",
    "        df['geneId'] = self.__filtered_anndata.var['geneId']\n",
    "        df['is_major'] = ''\n",
    "\n",
    "        for ct in self.__filtered_anndata.obs['cell_type'].unique():\n",
    "            # For each gene, pick transcript(s) with max usage in that group\n",
    "            df.loc[df[ct] == df.groupby('geneId')[ct].transform('max'), 'is_major'] += ct + ','\n",
    "\n",
    "        di = df['is_major'].to_dict()\n",
    "        d = {}\n",
    "        for (k, v) in di.items():\n",
    "            # count how many cell types this transcript was major in\n",
    "            d[k] = len(v.split(',')) - 1\n",
    "\n",
    "        # example logic: transcripts that are major in exactly 1 cell type\n",
    "        tr_ids = list(set(k for (k, v) in d.items() if v == 1))\n",
    "        return tr_ids\n",
    "\n",
    "    def find_major_minor_isoforms(self):\n",
    "        return self.__find_major_minor_isoforms()\n",
    "\n",
    "    ###########################################################################\n",
    "    # Plot a matrix of transcripts by cell type, using \"scattermap\"\n",
    "    ###########################################################################\n",
    "    def plot_relevant_genes(self, gene_id, p_value_threshold=0.05, data=None):\n",
    "        \"\"\"\n",
    "        For Dirichlet-based results (self.relevant_genes), generate a matrix\n",
    "        of transcripts vs. cell_types that had a p-value < threshold,\n",
    "        with circle color representing #nonzero usage, circle size representing sum of counts.\n",
    "        \"\"\"\n",
    "        if data is not None:\n",
    "            self.relevant_genes = data\n",
    "        if not hasattr(self, 'relevant_genes') or self.relevant_genes is None:\n",
    "            raise ValueError(\n",
    "                \"Please run `find_switching_isoforms(method='Dirichlet')` first to fill `self.relevant_genes`.\"\n",
    "            )\n",
    "\n",
    "        # Subset to this gene & p < threshold\n",
    "        subset = self.relevant_genes[\n",
    "            (self.relevant_genes['gene_id'] == gene_id) &\n",
    "            (self.relevant_genes['p_value'] < p_value_threshold)\n",
    "        ]\n",
    "        if subset.empty:\n",
    "            print(\"No results found for gene_id =\", gene_id)\n",
    "            return\n",
    "\n",
    "        # Collect cell types that appear in group_1 or group_2\n",
    "        ct_pairs = subset[['group_1', 'group_2']].values.tolist()\n",
    "        cell_types_compare = list({x for pair in ct_pairs for x in pair})\n",
    "\n",
    "        # Flatten all transcript IDs\n",
    "        tr_ids = subset['transcript_ids'].tolist()  # list of lists\n",
    "        tr_ids_flat = list({x for sublist in tr_ids for x in sublist})\n",
    "\n",
    "        # Prepare data\n",
    "        tmp = self.to_df().copy()\n",
    "        tmp['cell_type'] = self.obs['cell_type']\n",
    "        # sum across transcripts, grouping by cell_type\n",
    "        genes_sum = tmp[tmp['cell_type'].isin(cell_types_compare)][tr_ids_flat + ['cell_type']].groupby('cell_type').sum()\n",
    "        # #nonzero usage across transcripts\n",
    "        genes_nonzero = tmp[tmp['cell_type'].isin(cell_types_compare)].groupby('cell_type').apply(\n",
    "            lambda x: (x[tr_ids_flat] != 0).sum()\n",
    "        )\n",
    "\n",
    "        color_data = genes_nonzero[tr_ids_flat].to_numpy()\n",
    "        size_data = genes_sum[tr_ids_flat].to_numpy()\n",
    "        x_labels = tr_ids_flat\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = scattermap(\n",
    "            color_data, marker_size=size_data, square=True, cmap=\"Reds\",\n",
    "            cbar_kws={\"label\": \"Non-zeros\"},\n",
    "            xticklabels=x_labels, yticklabels=cell_types_compare\n",
    "        )\n",
    "        mk_size = 60\n",
    "        # For the legend, we'll show max, mean, min usage as example\n",
    "        ax.scatter(-1, -1, label=f\"{np.amax(size_data):0.1f}\", marker=\"o\", c=\"r\", s=mk_size)\n",
    "        ax.scatter(-1, -1, label=f\"{np.mean(size_data):0.1f}\", marker=\"o\", c=\"r\", s=mk_size*0.5)\n",
    "        if np.any(size_data > 0):\n",
    "            nz_min = np.amin(size_data[np.nonzero(size_data)])\n",
    "        else:\n",
    "            nz_min = 0.0\n",
    "        ax.scatter(-1, -1, label=f\"{nz_min:0.1f}\", marker=\"o\", c=\"r\", s=mk_size*0.1)\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1.27, -0.05))\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    ###########################################################################\n",
    "    # Simple summary plots of isoforms\n",
    "    ###########################################################################\n",
    "    def _plot_genes_cell_type(self, _ax):\n",
    "        # Summation of counts across transcripts, by cell type\n",
    "        df = pd.DataFrame(np.transpose(self.X), columns=self.obs['cell_type'])\n",
    "        df = df.sum(axis=0).to_frame().reset_index()\n",
    "        df.columns = ['cell_type', 'n_of_genes']\n",
    "\n",
    "        if _ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "            pal = [self.colors[i % len(self.colors)] for i in range(len(df['cell_type'].unique()))]\n",
    "            sns.boxplot(x='cell_type', y='n_of_genes', data=df, ax=ax, palette=pal)\n",
    "            sns.stripplot(x='cell_type', y='n_of_genes', data=df, color='black', size=1, ax=ax)\n",
    "            ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "            plt.show()\n",
    "        else:\n",
    "            pal = [self.colors[i % len(self.colors)] for i in range(len(df['cell_type'].unique()))]\n",
    "            sns.boxplot(x='cell_type', y='n_of_genes', data=df, ax=_ax, palette=pal)\n",
    "            sns.stripplot(x='cell_type', y='n_of_genes', data=df, color='black', size=1, ax=_ax)\n",
    "            _ax.set_xticklabels(_ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "    def plot_genes_cell_type(self):\n",
    "        self._plot_genes_cell_type(None)\n",
    "\n",
    "    def _plot_isoforms_frequencies(self, _ax):\n",
    "        \"\"\"\n",
    "        Plots how many genes have exactly k isoforms, for k=1,2,3,...\n",
    "        \"\"\"\n",
    "        iso_per_gene = self.gene_counts\n",
    "        # If the groupby gave 'geneId' as index, we have a column named e.g. \"index\"\n",
    "        # or it might have \"transcriptId\" as the count. Adjust if needed.\n",
    "        freq_counts = iso_per_gene['transcriptId'].value_counts()\n",
    "\n",
    "        if _ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "            freq_counts.plot(ax=ax, kind='bar',\n",
    "                             xlabel='Number of isoforms per gene',\n",
    "                             ylabel='Count of genes',\n",
    "                             color=self.colors[0])\n",
    "            plt.show()\n",
    "        else:\n",
    "            freq_counts.plot(ax=_ax, kind='bar',\n",
    "                             xlabel='Number of isoforms per gene',\n",
    "                             ylabel='Count of genes',\n",
    "                             color=self.colors[0])\n",
    "\n",
    "    def plot_isoforms_frequencies(self):\n",
    "        self._plot_isoforms_frequencies(None)\n",
    "\n",
    "    def _plot_switch_gen_bar(self, _ax):\n",
    "        \"\"\"\n",
    "        Shows fraction of genes that have multiple isoforms vs. single isoform,\n",
    "        plus total transcripts in an adjacent bar.\n",
    "        \"\"\"\n",
    "        iso_per_gene = self.gene_counts\n",
    "        multiple_iso = sum(iso_per_gene['transcriptId'] > 1)\n",
    "        mono_iso = sum(iso_per_gene['transcriptId'] <= 1)\n",
    "\n",
    "        lab_multi = f\"{100.0*multiple_iso/(multiple_iso+mono_iso):.1f}%\"\n",
    "        lab_mono = f\"{100.0*mono_iso/(multiple_iso+mono_iso):.1f}%\"\n",
    "\n",
    "        x = ['genes']\n",
    "        x_tr = ['transcripts']\n",
    "\n",
    "        if _ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.bar(x, multiple_iso, color=self.colors[0])\n",
    "            ax.bar(x, mono_iso, bottom=multiple_iso, color=self.colors[1])\n",
    "            ax.text(0, multiple_iso/2, lab_multi, ha=\"center\", va=\"center\", color=\"white\")\n",
    "            ax.text(0, multiple_iso + mono_iso/2, lab_mono, ha=\"center\", va=\"center\", color=\"white\")\n",
    "            # Show total transcripts\n",
    "            ax.bar(x_tr, len(self.var['transcriptId']), color=self.colors[2])\n",
    "            plt.show()\n",
    "        else:\n",
    "            _ax.bar(x, multiple_iso, color=self.colors[0])\n",
    "            _ax.bar(x, mono_iso, bottom=multiple_iso, color=self.colors[1])\n",
    "            _ax.text(0, multiple_iso/2, lab_multi, ha=\"center\", va=\"center\", color=\"white\")\n",
    "            _ax.text(0, multiple_iso + mono_iso/2, lab_mono, ha=\"center\", va=\"center\", color=\"white\")\n",
    "            _ax.bar(x_tr, len(self.var['transcriptId']), color=self.colors[2])\n",
    "\n",
    "    def plot_switch_gen_bar(self):\n",
    "        self._plot_switch_gen_bar(None)\n",
    "\n",
    "    def plot_isoforms_summary(self):\n",
    "        \"\"\"\n",
    "        Simple summary combining multiple subplots in one figure.\n",
    "        Adjust to your figure layout tools (e.g., plt.subplot) as needed.\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(14, 4))\n",
    "\n",
    "        ax1 = fig.add_subplot(131)\n",
    "        self._plot_switch_gen_bar(ax1)\n",
    "        ax1.set_title(\"Multiple isoforms genes %\")\n",
    "\n",
    "        ax2 = fig.add_subplot(132)\n",
    "        self._plot_isoforms_frequencies(ax2)\n",
    "        ax2.set_title(\"Frequency of isoforms per gene\")\n",
    "\n",
    "        ax3 = fig.add_subplot(133)\n",
    "        self._plot_genes_cell_type(ax3)\n",
    "        ax3.set_title(\"Nb of genes per cell type\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    ############################################################################\n",
    "    # Utility: look up transcript common names (e.g., from Ensembl) if needed\n",
    "    ############################################################################\n",
    "    def get_transcripts_common_names(self, transcript_ids):\n",
    "        \"\"\"\n",
    "        Calls Ensembl's REST API to get display_name for each transcript in transcript_ids.\n",
    "        If a transcript has a version (e.g., .N), we strip that before calling.\n",
    "        \"\"\"\n",
    "        tr_common_names = []\n",
    "        server = \"https://rest.ensembl.org\"\n",
    "\n",
    "        for tid in transcript_ids:\n",
    "            tid_stripped = tid.split('.')[0] if '.' in tid else tid\n",
    "            ext = f\"/lookup/id/{tid_stripped}?expand=1\"\n",
    "            r = requests.get(server + ext, headers={\"Content-Type\": \"application/json\"})\n",
    "            if not r.ok:\n",
    "                # returns display_name or raises\n",
    "                tr_common_names.append(tid)\n",
    "                continue\n",
    "            decoded = r.json()\n",
    "            tr_common_names.append(decoded.get('display_name', tid))\n",
    "\n",
    "        return tr_common_names\n",
    "\n",
    "    ############################################################################\n",
    "    # Transcript structure drawing (simple Ensembl exons)\n",
    "    ############################################################################\n",
    "    def __get_coord_from_tscrpt_id(self, transcript_id):\n",
    "        \"\"\"\n",
    "        Query Ensembl for the exon coordinates for the given transcript.\n",
    "        Return (list_of_exons, strand).\n",
    "        Each element in list_of_exons is a dict with 'start'/'end' from Ensembl.\n",
    "        \"\"\"\n",
    "        tid_stripped = transcript_id.split('.')[0] if '.' in transcript_id else transcript_id\n",
    "        server = \"https://rest.ensembl.org\"\n",
    "        ext = f\"/lookup/id/{tid_stripped}?expand=1\"\n",
    "        r = requests.get(server+ext, headers={\"Content-Type\": \"application/json\"})\n",
    "        if not r.ok:\n",
    "            r.raise_for_status()\n",
    "\n",
    "        decoded = r.json()\n",
    "        exon_list = decoded.get('Exon', [])\n",
    "        exons = []\n",
    "        for e in exon_list:\n",
    "            exons.append((e['start'], e['end']))\n",
    "        strand = decoded.get('strand', 1)\n",
    "        return exons, strand\n",
    "\n",
    "    def __draw_exons(self, exons, strand, color, transcript_name,\n",
    "                     offset=0, start_override=None, end_override=None, no_render=False):\n",
    "        \"\"\"\n",
    "        Draw a schematic of exons for a single transcript.\n",
    "        If 'strand' == 1, arrow goes left->right, else reversed.\n",
    "        If 'start_override'/'end_override' are set, we use them to scale everything.\n",
    "        \"\"\"\n",
    "        if not no_render:\n",
    "            plt.axes()\n",
    "            plt.xlim((-0.1, 1))\n",
    "            plt.ylim((-0.3, 0.3))\n",
    "            plt.margins(0.2)\n",
    "            plt.axis('off')\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(20, 2)\n",
    "\n",
    "        height = 0.2\n",
    "        if strand == 1:\n",
    "            exons_sorted = sorted(exons, key=lambda x: x[0])  # sort by start\n",
    "            real_start, real_end = exons_sorted[0][0], exons_sorted[-1][1]\n",
    "        else:\n",
    "            exons_sorted = sorted(exons, key=lambda x: x[0], reverse=True)\n",
    "            real_start, real_end = exons_sorted[-1][0], exons_sorted[0][1]\n",
    "\n",
    "        if start_override is not None and end_override is not None:\n",
    "            pos_start = start_override\n",
    "            pos_end = end_override\n",
    "        else:\n",
    "            pos_start, pos_end = real_start, real_end\n",
    "\n",
    "        total_length = pos_end - pos_start\n",
    "        total_length_with_margin = 1.05 * total_length\n",
    "        pos_start_margin = pos_start - 0.025 * total_length\n",
    "\n",
    "        # draw the exon rectangles\n",
    "        for (s, e) in exons_sorted:\n",
    "            left = (s - pos_start_margin) / total_length_with_margin\n",
    "            w = (e - s) / total_length_with_margin\n",
    "            rect = plt.Rectangle((left, offset), w, height, fc=color, ec=\"black\")\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "        # draw an arrow line\n",
    "        if len(exons) > 1:\n",
    "            if strand < 0:\n",
    "                # arrow from right to left\n",
    "                arrow = plt.arrow(1, offset - height/4, -1, 0,\n",
    "                                  width=0.0015, head_length=0.01, head_width=0.1,\n",
    "                                  length_includes_head=True, overhang=1)\n",
    "            else:\n",
    "                # arrow from left to right\n",
    "                arrow = plt.arrow(0, offset - height/4, 1, 0,\n",
    "                                  width=0.0015, head_length=0.01, head_width=0.1,\n",
    "                                  length_includes_head=True, overhang=1)\n",
    "            plt.gca().add_patch(arrow)\n",
    "\n",
    "        # draw start & end tick marks\n",
    "        x_start = (real_start - pos_start_margin) / total_length_with_margin\n",
    "        x_end = (real_end - pos_start_margin) / total_length_with_margin\n",
    "\n",
    "        plt.plot([x_start, x_start],\n",
    "                 [offset - height/4 - 0.03, offset - height/4 + 0.03],\n",
    "                 color='black')\n",
    "        plt.plot([x_end, x_end],\n",
    "                 [offset - height/4 - 0.03, offset - height/4 + 0.03],\n",
    "                 color='black')\n",
    "\n",
    "        plt.text(x_start, offset - height/4 - 0.075,\n",
    "                 str(real_start), ha='center', va='center', fontsize=9)\n",
    "        plt.text(x_end, offset - height/4 - 0.075,\n",
    "                 str(real_end), ha='center', va='center', fontsize=9)\n",
    "\n",
    "        plt.text(1, offset - height,\n",
    "                 transcript_name, ha='right', va='top', fontsize=12)\n",
    "\n",
    "        if not no_render:\n",
    "            plt.show()\n",
    "\n",
    "    def __get_transcripts_from_gene(self, gene_name):\n",
    "        \"\"\"\n",
    "        Return the transcriptIds in self.var that match the given geneId.\n",
    "        \"\"\"\n",
    "        if 'geneId' not in self.var.columns:\n",
    "            return []\n",
    "        mask = (self.var['geneId'] == gene_name)\n",
    "        return self.var.loc[mask, 'transcriptId'].tolist()\n",
    "\n",
    "    def __draw_transcripts_list(self, gene_name, trs_to_show, _ax, colors=None):\n",
    "        \"\"\"\n",
    "        Draw multiple transcripts for a single gene, stacked.\n",
    "        Each transcript's exons are displayed horizontally.\n",
    "        \"\"\"\n",
    "        if trs_to_show == []:\n",
    "            transcripts_id = self.__get_transcripts_from_gene(gene_name)\n",
    "        else:\n",
    "            transcripts_id = trs_to_show\n",
    "\n",
    "        exons_list = []\n",
    "        strands = []\n",
    "        for tid in transcripts_id:\n",
    "            exons, strand = self.__get_coord_from_tscrpt_id(tid)\n",
    "            exons_list.append(exons)\n",
    "            strands.append(strand)\n",
    "\n",
    "        # pick colors\n",
    "        if colors is None:\n",
    "            pal = ['#898D90', '#8D93A1', '#9F99B5', '#AFACC9',\n",
    "                   '#D7CADE', '#DAEDF3', '#F7EABD']\n",
    "            colors = [pal[i % len(pal)] for i in range(len(exons_list))]\n",
    "\n",
    "        # get overall min start and max end for scaling\n",
    "        def get_limits(e_list, s_list):\n",
    "            start_lim = sys.maxsize\n",
    "            end_lim = -sys.maxsize\n",
    "            for e, s in zip(e_list, s_list):\n",
    "                if s == 1:\n",
    "                    s0, e0 = sorted(e, key=lambda x: x[0])[0][0], sorted(e, key=lambda x: x[0])[-1][1]\n",
    "                else:\n",
    "                    s0, e0 = sorted(e, key=lambda x: x[0])[0][0], sorted(e, key=lambda x: x[0])[-1][1]\n",
    "                start_lim = min(start_lim, s0)\n",
    "                end_lim = max(end_lim, e0)\n",
    "            return (start_lim, end_lim)\n",
    "\n",
    "        if len(exons_list) == 0:\n",
    "            print(f\"No transcripts found for gene: {gene_name}\")\n",
    "            return\n",
    "\n",
    "        (start_global, end_global) = get_limits(exons_list, strands)\n",
    "\n",
    "        # set up the final figure space\n",
    "        plt.axes()\n",
    "        plt.xlim((-0.1, 1.1))\n",
    "        plt.ylim((0.1 - 0.5*len(exons_list), 0.3))\n",
    "        plt.margins(0.2)\n",
    "        plt.axis('off')\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(20, len(exons_list)*2)\n",
    "\n",
    "        # stack them\n",
    "        for i, (ex, st, col, tname) in enumerate(zip(exons_list, strands, colors, transcripts_id)):\n",
    "            offset = -0.5*i\n",
    "            self.__draw_exons(\n",
    "                ex, st, col, tname, offset=offset,\n",
    "                start_override=start_global, end_override=end_global,\n",
    "                no_render=True\n",
    "            )\n",
    "\n",
    "        if _ax is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            return plt\n",
    "\n",
    "    def draw_transcripts_list(self, gene_name, colors=None):\n",
    "        \"\"\"\n",
    "        Draw all transcripts for a gene, each stacked horizontally with exons.\n",
    "        \"\"\"\n",
    "        self.__draw_transcripts_list(gene_name, [], None, colors)\n",
    "\n",
    "    ###########################################################################\n",
    "    # Quick expression box/violin plot per transcript\n",
    "    ###########################################################################\n",
    "    def _trsct_counts_cell_type(self, gene_name, trs_to_show, _ax):\n",
    "        \"\"\"\n",
    "        For a given gene, gather counts across transcripts for each cell_type, then plot.\n",
    "        \"\"\"\n",
    "        df = self.__filtered_anndata.to_df().set_index(self.__filtered_anndata.obs['cell_type'])\n",
    "        df = df.transpose()\n",
    "        df[['transcriptId', 'geneId']] = self.__filtered_anndata.var[['transcriptId', 'geneId']]\n",
    "\n",
    "        gene_iso_count = df[df['geneId'] == gene_name].drop('geneId', axis=1).set_index('transcriptId').transpose()\n",
    "        melted = gene_iso_count.reset_index().melt(\n",
    "            id_vars='cell_type', var_name='transcriptId', value_name='count'\n",
    "        )\n",
    "\n",
    "        if trs_to_show:\n",
    "            melted = melted[melted['transcriptId'].isin(trs_to_show)]\n",
    "\n",
    "        if _ax is None:\n",
    "            g = sns.catplot(\n",
    "                x=\"cell_type\", y=\"count\", col=\"transcriptId\",\n",
    "                aspect=1, dodge=False, kind=\"violin\", data=melted\n",
    "            )\n",
    "            g.set_titles(col_template=\"{col_name}\", size=8)\n",
    "            g.set_xticklabels(rotation=90)\n",
    "            g.fig.suptitle(gene_name)\n",
    "            plt.show()\n",
    "        else:\n",
    "            g = sns.catplot(\n",
    "                x=\"cell_type\", y=\"count\", col=\"transcriptId\",\n",
    "                aspect=1, dodge=False, kind=\"violin\", data=melted\n",
    "            )\n",
    "            g.set_titles(col_template=\"{col_name}\", size=8)\n",
    "            g.set_xticklabels(rotation=90)\n",
    "            g.fig.suptitle(gene_name)\n",
    "            return g\n",
    "\n",
    "    def trsct_counts_cell_type(self, gene_name, trs_to_show=[]):\n",
    "        \"\"\"\n",
    "        Convenience wrapper to show transcript counts for the given gene across cell types.\n",
    "        \"\"\"\n",
    "        self._trsct_counts_cell_type(gene_name, trs_to_show, None)\n",
    "\n",
    "    def plot_switching_isoforms_boxplot(self, gene_name, trs_to_show=[]):\n",
    "        \"\"\"\n",
    "        Another example that draws boxen plots per transcript across cell_type.\n",
    "        \"\"\"\n",
    "        fig = plt.figure()\n",
    "        subset = self[:, self.var[\"geneId\"] == gene_name].to_df()\n",
    "        subset['cell_type'] = self.obs['cell_type']\n",
    "\n",
    "        if trs_to_show:\n",
    "            subset = subset[trs_to_show + ['cell_type']]\n",
    "\n",
    "        data = pd.melt(subset, id_vars=['cell_type'],\n",
    "                       var_name='transcriptId', value_name='count')\n",
    "        ax = fig.add_subplot()\n",
    "        g = sns.catplot(\n",
    "            ax=ax, x=\"cell_type\", y=\"count\", col=\"transcriptId\",\n",
    "            aspect=0.5, dodge=False, kind=\"boxen\", data=data,\n",
    "            flier_kws=dict(marker='.', linewidth=0.5),\n",
    "            palette=self.colors\n",
    "        )\n",
    "        g.fig.set_size_inches(15, 8)\n",
    "        g.set_xticklabels(rotation=90)\n",
    "\n",
    "    def draw_gene_summary(self, gene_name, trs_to_show=[]):\n",
    "        \"\"\"\n",
    "        Example that composes multiple subplots: a violin plot by cell_type,\n",
    "        a stacked bar usage plot, and the transcripts structure diagram.\n",
    "        You can adapt to your own figure arrangement library or approach.\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "        # 1. Transcript counts (violin)\n",
    "        ax1 = fig.add_subplot(311)\n",
    "        df = self.__filtered_anndata.to_df().set_index(self.__filtered_anndata.obs['cell_type'])\n",
    "        df = df.transpose()\n",
    "        df[['transcriptId', 'geneId']] = self.__filtered_anndata.var[['transcriptId', 'geneId']]\n",
    "        gene_iso_count = df[df['geneId'] == gene_name].drop('geneId', axis=1).set_index('transcriptId').transpose()\n",
    "        melted = gene_iso_count.reset_index().melt(\n",
    "            id_vars='cell_type', var_name='transcriptId', value_name='count'\n",
    "        )\n",
    "        if trs_to_show:\n",
    "            melted = melted[melted['transcriptId'].isin(trs_to_show)]\n",
    "        sns.violinplot(x=\"cell_type\", y=\"count\", hue=\"transcriptId\",\n",
    "                       data=melted, ax=ax1, split=True)\n",
    "        ax1.set_title(f\"{gene_name} transcript counts by cell type\", fontsize=10)\n",
    "        ax1.legend(bbox_to_anchor=(1.01, 1), loc=2)\n",
    "        ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "\n",
    "        # 2. Bar plot of transcript usage\n",
    "        ax2 = fig.add_subplot(312)\n",
    "        grouped = self.__filtered_anndata.obsm['Iso_prct'].copy()\n",
    "        grouped['cell_type'] = self.__filtered_anndata.obs['cell_type']\n",
    "        res = grouped.groupby('cell_type').mean().transpose()\n",
    "        res = res.assign(transcriptId=self.__filtered_anndata.var['transcriptId'].to_list())\n",
    "        res = res.assign(geneId=self.__filtered_anndata.var['geneId'].to_list())\n",
    "        subres = res[res['geneId'] == gene_name].drop(['geneId'], axis=1)\n",
    "        if trs_to_show:\n",
    "            subres = subres[subres['transcriptId'].isin(trs_to_show)]\n",
    "        plot_data = subres.set_index('transcriptId').transpose()\n",
    "        plot_data.plot(kind='barh', stacked=True, ax=ax2)\n",
    "        ax2.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "        ax2.set_title(f\"{gene_name} stacked usage by cell type\", fontsize=10)\n",
    "\n",
    "        # 3. Exon structure (transcript diagram)\n",
    "        ax3 = fig.add_subplot(313)\n",
    "        self.__draw_transcripts_list(gene_name, trs_to_show, ax3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489add128907b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_iso_adata(\n",
    "    path: str  # Path to a tab-separated file, typically the Sicelore output with transcript counts.\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an AnnData object containing isoform counts from a Sicelore output file.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): Path to the input file, which is expected to be tab-separated and contain:\n",
    "        - `transcriptId`: Transcript identifiers.\n",
    "        - `geneId`: Gene identifiers.\n",
    "        - Transcript counts for individual barcodes (cells) as additional columns.\n",
    "\n",
    "    Returns:\n",
    "    - adata_iso (AnnData): An AnnData object with isoform counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input file and read it into a Pandas DataFrame\n",
    "    with open(path) as isoforms:\n",
    "        df = pd.read_table(isoforms, sep='\\t')\n",
    "\n",
    "    # Extract the count matrix\n",
    "    # - `df.iloc[0:, 2:]`: assuming these are counts.\n",
    "    counts = df.iloc[0:, 2:]\n",
    "\n",
    "    # Create an AnnData object with the count matrix\n",
    "\n",
    "    adata_iso = ad.AnnData(counts).transpose()\n",
    "\n",
    "    # Assign transcript IDs as variable names (columns in the original file)\n",
    "    adata_iso.var_names = df['transcriptId'].to_list()\n",
    "\n",
    "    # Add additional variable-level metadata\n",
    "    # - Include both `transcriptId` and `geneId` as annotations for the variables.\n",
    "    adata_iso.var = df[['transcriptId', 'geneId']]\n",
    "\n",
    "    # Create observation-level metadata for barcodes (cells)\n",
    "    # - Extract column names (barcodes) starting from the 3rd column (index 2).\n",
    "    barcodes = {'barcodes': df.columns.values[2:]}\n",
    "    barcodes = pd.DataFrame(data=barcodes)\n",
    "\n",
    "    # Assign the barcodes DataFrame to the AnnData object as observation metadata\n",
    "    adata_iso.obs = barcodes\n",
    "\n",
    "    # Set observation names (row indices) in the AnnData object to match the barcodes\n",
    "    adata_iso.obs_names = barcodes['barcodes'].tolist()\n",
    "\n",
    "    # Return the AnnData object containing isoform counts\n",
    "    return adata_iso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
