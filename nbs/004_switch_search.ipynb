{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179f3cd8114dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa090e541302e3",
   "metadata": {},
   "outputs": [],
   "source": "#| default_exp switch_search"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import sys\n",
    "import patchworklib as pw\n",
    "import urllib\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gammaln\n",
    "from scipy.optimize import minimize\n",
    "from itertools import combinations\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "from functools import lru_cache\n",
    "import pyranges as pr\n",
    "from pyfaidx import Fasta\n",
    "import logging\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from allos.anndata_iso import AnnDataIso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319a1177ddfc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class SwitchSearch(AnnDataIso):\n",
    "    def __perform_mle(self, data, total_counts):\n",
    "        \"\"\"\n",
    "        SciPy-based Dirichlet-Multinomial MLE.\n",
    "\n",
    "        data: (M x K) torch.Tensor of counts\n",
    "        total_counts: (M,) torch.Tensor of row sums\n",
    "        Returns: (nll, alpha_hat)\n",
    "        \"\"\"\n",
    "        data_np = data.detach().cpu().numpy()        # shape (M, K)\n",
    "        total_counts_np = total_counts.detach().cpu().numpy()  # shape (M,)\n",
    "\n",
    "        # We don't strictly need total_counts_np for the objective,\n",
    "        # since it's implicit in row sums of data_np.\n",
    "\n",
    "        K = data_np.shape[1]\n",
    "\n",
    "        def objective(alpha):\n",
    "            def _dirichlet_multinomial_nll(alpha, data_np):\n",
    "                \"\"\"\n",
    "                Compute the negative log-likelihood for a Dirichlet-Multinomial model,\n",
    "                given 'data_np' (shape M x K) and 'alpha' (shape K, > 0).\n",
    "                Omits the factorial terms that don't depend on alpha.\n",
    "                \"\"\"\n",
    "                if np.any(alpha <= 0):\n",
    "                    return np.inf\n",
    "\n",
    "                alpha_sum = np.sum(alpha)\n",
    "                nll = 0.0\n",
    "                for row in data_np:\n",
    "                    N = np.sum(row)\n",
    "                    # part that depends on alpha_sum\n",
    "                    nll -= gammaln(alpha_sum)\n",
    "                    nll += gammaln(alpha_sum + N)\n",
    "                    # part that depends on alpha_j\n",
    "                    for j in range(len(alpha)):\n",
    "                        nll -= (gammaln(alpha[j] + row[j]) - gammaln(alpha[j]))\n",
    "                return float(nll)\n",
    "            return _dirichlet_multinomial_nll(alpha, data_np)\n",
    "\n",
    "        init_alpha = np.ones(K) + 0.1\n",
    "        bounds = [(1e-9, None)] * K\n",
    "\n",
    "        result = minimize(\n",
    "            fun=objective,\n",
    "            x0=init_alpha,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds,\n",
    "            options={'maxiter': 10000, 'ftol': 1e-5}\n",
    "        )\n",
    "        if not result.success:\n",
    "            print(f\"[Warning] MLE not converged: {result.message}\")\n",
    "\n",
    "        return float(result.fun), result.x\n",
    "\n",
    "    def __LRT_test(self, data1, data2):\n",
    "        \"\"\"\n",
    "        Perform the LRT:\n",
    "          - Fit combined data => loss_full\n",
    "          - Fit data1 alone => loss1\n",
    "          - Fit data2 alone => loss2\n",
    "          => chi2 = 2 * (loss_full - (loss1 + loss2))\n",
    "          p-value from Chi2(K).\n",
    "        \"\"\"\n",
    "        total_counts1 = data1.sum(dim=-1).float()\n",
    "        total_counts2 = data2.sum(dim=-1).float()\n",
    "        combined_data = torch.cat([data1, data2], dim=0)\n",
    "        combined_counts = torch.cat([total_counts1, total_counts2], dim=0)\n",
    "\n",
    "        # Full model\n",
    "        loss_full, alpha_full = self.__perform_mle(combined_data, combined_counts)\n",
    "        # data1 alone\n",
    "        loss1, alpha1 = self.__perform_mle(data1, total_counts1)\n",
    "        # data2 alone\n",
    "        loss2, alpha2 = self.__perform_mle(data2, total_counts2)\n",
    "\n",
    "        chi2_stat = 2.0 * (loss_full - (loss1 + loss2))\n",
    "        if chi2_stat < 0:\n",
    "            return float('nan'), float('nan'), alpha_full, alpha1, alpha2\n",
    "\n",
    "        # Degrees of freedom = K\n",
    "        K = data1.size(1)\n",
    "        chi2_val = torch.tensor(chi2_stat, dtype=torch.float)\n",
    "        p_value = 1.0 - torch.distributions.Chi2(df=K).cdf(chi2_val).item()\n",
    "\n",
    "        return chi2_stat, p_value, alpha_full, alpha1, alpha2\n",
    "\n",
    "    def __compare_groups(self, group_1_label, group_2_label, cell_group_column, gene_id):\n",
    "        group_1 = self[self.obs[cell_group_column] == group_1_label]\n",
    "        group_2 = self[self.obs[cell_group_column] == group_2_label]\n",
    "\n",
    "        data1 = torch.tensor(\n",
    "            group_1[:, group_1.var['geneId'] == gene_id].X.toarray(), dtype=torch.float\n",
    "        )\n",
    "        data2 = torch.tensor(\n",
    "            group_2[:, group_2.var['geneId'] == gene_id].X.toarray(), dtype=torch.float\n",
    "        )\n",
    "\n",
    "        total_counts1 = data1.sum(dim=-1)\n",
    "        total_counts2 = data2.sum(dim=-1)\n",
    "        non_zero_indices1 = total_counts1 > 9\n",
    "        non_zero_indices2 = total_counts2 > 9\n",
    "        data1 = data1[non_zero_indices1]\n",
    "        data2 = data2[non_zero_indices2]\n",
    "        total_counts1 = total_counts1[non_zero_indices1].float()\n",
    "        total_counts2 = total_counts2[non_zero_indices2].float()\n",
    "\n",
    "        if data1.size(0) == 0 or data2.size(0) == 0:\n",
    "            return None\n",
    "\n",
    "        chi2_stat, p_value, alpha_combined, alpha1, alpha2 = self.__LRT_test(data1, data2)\n",
    "        if not np.isnan(chi2_stat):\n",
    "            return {\n",
    "                \"chi2_stat\": chi2_stat,\n",
    "                \"p_value\": p_value,\n",
    "                \"alpha_combined\": alpha_combined.tolist(),\n",
    "                \"alpha1\": alpha1.tolist(),\n",
    "                \"alpha2\": alpha2.tolist()\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def __filter_genes(self, group_1_label, group_2_label, cell_group_column, min_count=9, min_diff=0.1):\n",
    "        group_1 = self[self.obs[cell_group_column] == group_1_label]\n",
    "        group_2 = self[self.obs[cell_group_column] == group_2_label]\n",
    "\n",
    "        gene_counts_group_1 = np.array(group_1.X.sum(axis=0)).flatten()\n",
    "        gene_counts_group_2 = np.array(group_2.X.sum(axis=0)).flatten()\n",
    "        total_gene_counts = gene_counts_group_1 + gene_counts_group_2\n",
    "\n",
    "        valid_genes = total_gene_counts > min_count\n",
    "        adata = self[:, valid_genes]\n",
    "\n",
    "        group_1 = adata[adata.obs[cell_group_column] == group_1_label]\n",
    "        group_2 = adata[adata.obs[cell_group_column] == group_2_label]\n",
    "\n",
    "        non_zero_genes_group_1 = np.array((group_1.X != 0).sum(axis=0)).flatten() > min_count\n",
    "        non_zero_genes_group_2 = np.array((group_2.X != 0).sum(axis=0)).flatten() > min_count\n",
    "        valid_genes = non_zero_genes_group_1 & non_zero_genes_group_2\n",
    "        filtered_with_valid_genes = adata[:, valid_genes]\n",
    "        for gene_id in np.concatenate((group_1.var['geneId'], group_2.var['geneId'])):\n",
    "            percent_1 = group_1[:, group_1.var['geneId'] == gene_id]\n",
    "            percent_2 = group_2[:, group_2.var['geneId'] == gene_id]\n",
    "            percent_1_X = percent_1.X.astype(float)\n",
    "            percent_2_X = percent_2.X.astype(float)\n",
    "            percent_1_X = percent_1_X / float(sum(percent_1_X.sum(axis=0)))\n",
    "            percent_2_X = percent_2_X / float(sum(percent_2_X.sum(axis=0)))\n",
    "            percent_1.layers['percent'] = percent_1_X\n",
    "            percent_2.layers['percent'] = percent_2_X\n",
    "            diff = False\n",
    "            for transcript_id in np.concatenate((\n",
    "                group_1[:, group_1.var['geneId'] == gene_id].var['transcriptId'],\n",
    "                group_2[:, group_2.var['geneId'] == gene_id].var['transcriptId']\n",
    "            ), axis=0):\n",
    "                per1 = percent_1[:, percent_1.var['transcriptId'] == transcript_id].layers['percent'].sum(axis=0)\n",
    "                per2 = percent_2[:, percent_2.var['transcriptId'] == transcript_id].layers['percent'].sum(axis=0)\n",
    "                diff = abs(per1 - per2) > min_diff\n",
    "                if diff:\n",
    "                    break\n",
    "            if not diff:\n",
    "                filtered_with_valid_genes = filtered_with_valid_genes[:, filtered_with_valid_genes.var['geneId'] != gene_id]\n",
    "\n",
    "        return SwitchSearch(filtered_with_valid_genes, self.obs['cell_type'])\n",
    "\n",
    "    def __find_major_minor_isoforms(self):\n",
    "        df = self._filtered_anndata.to_df()\n",
    "        df['cell_type'] = self._filtered_anndata.obs['cell_type']\n",
    "        df = df.groupby('cell_type').mean().transpose()\n",
    "        df['geneId'] = self._filtered_anndata.var['geneId']\n",
    "        df['is_major'] = ''\n",
    "        for ct in self._filtered_anndata.obs['cell_type'].unique():\n",
    "            df.loc[df[ct] == df.groupby('geneId')[ct].transform('max'), 'is_major'] += ct + ','\n",
    "        di = df['is_major'].to_dict()\n",
    "        d = dict()\n",
    "        for (k, v) in di.items():\n",
    "            d[k] = len(v.split(',')) - 1\n",
    "        tr_ids = list(set(k for (k, v) in d.items() if v == 1))\n",
    "        return tr_ids\n",
    "\n",
    "    def find_major_minor_isoforms(self):\n",
    "        return self.__find_major_minor_isoforms()\n",
    "\n",
    "    ###############################################################\n",
    "    # Helper function for Dirichlet-Multinomial Negative Log-Likelihood\n",
    "    ###############################################################\n",
    "    def _dirichlet_multinomial_nll(self, alpha, data_np):\n",
    "        \"\"\"\n",
    "        Compute the negative log-likelihood for a Dirichlet-Multinomial model,\n",
    "        given 'data_np' (shape M x K) and 'alpha' (shape K, > 0).\n",
    "        Omits the factorial terms that don't depend on alpha.\n",
    "        \"\"\"\n",
    "        if np.any(alpha <= 0):\n",
    "            return np.inf\n",
    "\n",
    "        alpha_sum = np.sum(alpha)\n",
    "        nll = 0.0\n",
    "        for row in data_np:\n",
    "            N = np.sum(row)\n",
    "            # part that depends on alpha_sum\n",
    "            nll -= gammaln(alpha_sum)\n",
    "            nll += gammaln(alpha_sum + N)\n",
    "            # part that depends on alpha_j\n",
    "            for j in range(len(alpha)):\n",
    "                nll -= (gammaln(alpha[j] + row[j]) - gammaln(alpha[j]))\n",
    "        return float(nll)\n",
    "\n",
    "    def _dm_mle(self, data):\n",
    "        \"\"\"\n",
    "        SciPy-based Dirichlet-Multinomial MLE on a NumPy array.\n",
    "        data: (M, K)\n",
    "        Returns: (nll, alpha_hat)\n",
    "        \"\"\"\n",
    "        K = data.shape[1]\n",
    "\n",
    "        def objective(alpha):\n",
    "            return self._dirichlet_multinomial_nll(alpha, data)\n",
    "\n",
    "        init_alpha = np.ones(K) + 0.1\n",
    "        bounds = [(1e-9, None)] * K\n",
    "\n",
    "        result = minimize(\n",
    "            fun=objective,\n",
    "            x0=init_alpha,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds,\n",
    "            options={'maxiter': 10000, 'ftol': 1e-5}\n",
    "        )\n",
    "        if not result.success:\n",
    "            return float('nan'), np.zeros(K)\n",
    "\n",
    "        return float(result.fun), result.x\n",
    "\n",
    "\n",
    "    def __fit_single_group(self, group_label, gene_id, cell_group_column='cell_type'):\n",
    "        \"\"\"\n",
    "        Returns (nll, alpha) for a single group's data on a given gene,\n",
    "        filtered to rows with sum > 9. Uses and updates self._single_fit_cache.\n",
    "        If no data remains after filtering, returns (np.nan, None).\n",
    "        \"\"\"\n",
    "        cache_key = (group_label, gene_id)\n",
    "        if cache_key in self._single_fit_cache:\n",
    "            return self._single_fit_cache[cache_key]\n",
    "\n",
    "        group_data = self[self.obs[cell_group_column] == group_label]\n",
    "        mask_gene = (group_data.var['geneId'] == gene_id)\n",
    "        data = group_data[:, mask_gene].X.toarray()\n",
    "        total_counts = data.sum(axis=1)\n",
    "        data = data[total_counts > 9]  # filter\n",
    "\n",
    "        if data.shape[0] == 0:\n",
    "            self._single_fit_cache[cache_key] = (np.nan, None)\n",
    "            return (np.nan, None)\n",
    "\n",
    "        nll, alpha = self._dm_mle(data)\n",
    "        self._single_fit_cache[cache_key] = (nll, alpha)\n",
    "        return (nll, alpha)\n",
    "\n",
    "    def __fit_combined(self, group_label1, group_label2, gene_id, cell_group_column='cell_type'):\n",
    "        \"\"\"\n",
    "        Returns (nll, alpha) for the combined data from group_label1+group_label2\n",
    "        on a given gene, filtered. Uses and updates self._combined_fit_cache.\n",
    "        If no data remains after filtering, returns (np.nan, None).\n",
    "        \"\"\"\n",
    "        cache_key = (group_label1, group_label2, gene_id)\n",
    "        if cache_key in self._combined_fit_cache:\n",
    "            return self._combined_fit_cache[cache_key]\n",
    "\n",
    "        group1 = self[self.obs[cell_group_column] == group_label1]\n",
    "        mask1 = (group1.var['geneId'] == gene_id)\n",
    "        data1 = group1[:, mask1].X.toarray()\n",
    "        total_counts1 = data1.sum(axis=1)\n",
    "        data1 = data1[total_counts1 > 9]\n",
    "\n",
    "        group2 = self[self.obs[cell_group_column] == group_label2]\n",
    "        mask2 = (group2.var['geneId'] == gene_id)\n",
    "        data2 = group2[:, mask2].X.toarray()\n",
    "        total_counts2 = data2.sum(axis=1)\n",
    "        data2 = data2[total_counts2 > 9]\n",
    "\n",
    "        if data1.shape[0] == 0 or data2.shape[0] == 0:\n",
    "            self._combined_fit_cache[cache_key] = (np.nan, None)\n",
    "            return (np.nan, None)\n",
    "\n",
    "        combined_data = np.vstack([data1, data2])\n",
    "        nll, alpha = self._dm_mle(combined_data)\n",
    "        self._combined_fit_cache[cache_key] = (nll, alpha)\n",
    "        return (nll, alpha)\n",
    "\n",
    "    def __cached_LRT_test(self, group_label1, group_label2, gene_id, cell_group_column='cell_type'):\n",
    "        \"\"\"\n",
    "        Use the cached single-group fits for group_label1, group_label2\n",
    "        plus a cached combined fit for (group_label1, group_label2).\n",
    "        Then do the LRT. Returns (chi2, p_value, alpha_full, alpha1, alpha2) or None.\n",
    "        \"\"\"\n",
    "        loss1, alpha1 = self.__fit_single_group(group_label1, gene_id, cell_group_column)\n",
    "        loss2, alpha2 = self.__fit_single_group(group_label2, gene_id, cell_group_column)\n",
    "        if alpha1 is None or alpha2 is None or np.isnan(loss1) or np.isnan(loss2):\n",
    "            return None\n",
    "\n",
    "        loss_full, alpha_full = self.__fit_combined(group_label1, group_label2, gene_id, cell_group_column)\n",
    "        if alpha_full is None or np.isnan(loss_full):\n",
    "            return None\n",
    "\n",
    "        chi2_stat = 2.0 * (loss_full - (loss1 + loss2))\n",
    "        if chi2_stat < 0:\n",
    "            return None\n",
    "\n",
    "        # Degrees of freedom = K\n",
    "        K = len(alpha_full)\n",
    "        p_value = 1.0 - chi2.cdf(chi2_stat, df=K)\n",
    "        return chi2_stat, p_value, alpha_full, alpha1, alpha2\n",
    "\n",
    "    def __compare_groups(self, group_1_label, group_2_label, cell_group_column, gene_id):\n",
    "        result = self.__cached_LRT_test(group_1_label, group_2_label, gene_id, cell_group_column)\n",
    "        if result is None:\n",
    "            return None\n",
    "\n",
    "        chi2_stat, p_value, alpha_combined, alpha1, alpha2 = result\n",
    "        transcript_ids = self.var_names[self.var['geneId'] == gene_id].tolist()\n",
    "        return {\n",
    "            \"chi2_stat\": chi2_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"alpha_combined\": alpha_combined.tolist(),\n",
    "            \"alpha1\": alpha1.tolist(),\n",
    "            \"alpha2\": alpha2.tolist(),\n",
    "            \"transcript_ids\": transcript_ids\n",
    "        }\n",
    "\n",
    "    def __filter_genes(self, group_1_label, group_2_label, cell_group_column, min_count=9, min_diff=0.1):\n",
    "        group_1 = self[self.obs[cell_group_column] == group_1_label]\n",
    "        group_2 = self[self.obs[cell_group_column] == group_2_label]\n",
    "\n",
    "        gene_counts_group_1 = np.array(group_1.X.sum(axis=0)).flatten()\n",
    "        gene_counts_group_2 = np.array(group_2.X.sum(axis=0)).flatten()\n",
    "        total_gene_counts = gene_counts_group_1 + gene_counts_group_2\n",
    "\n",
    "        valid_genes_mask = total_gene_counts > min_count\n",
    "        adata_slice = self[:, valid_genes_mask]\n",
    "\n",
    "        group_1_slice = adata_slice[adata_slice.obs[cell_group_column] == group_1_label]\n",
    "        group_2_slice = adata_slice[adata_slice.obs[cell_group_column] == group_2_label]\n",
    "\n",
    "        non_zero_genes_group_1 = (group_1_slice.X != 0).sum(axis=0) > min_count\n",
    "        non_zero_genes_group_2 = (group_2_slice.X != 0).sum(axis=0) > min_count\n",
    "        final_valid_genes = non_zero_genes_group_1 & non_zero_genes_group_2\n",
    "        filtered_with_valid_genes = adata_slice[:, final_valid_genes]\n",
    "\n",
    "        # Additional pass to exclude genes whose transcripts do not differ enough in % usage\n",
    "        for gene_id in np.unique(filtered_with_valid_genes.var['geneId']):\n",
    "            sub1 = filtered_with_valid_genes[\n",
    "                filtered_with_valid_genes.obs[cell_group_column] == group_1_label,\n",
    "                filtered_with_valid_genes.var['geneId'] == gene_id\n",
    "            ]\n",
    "            sub2 = filtered_with_valid_genes[\n",
    "                filtered_with_valid_genes.obs[cell_group_column] == group_2_label,\n",
    "                filtered_with_valid_genes.var['geneId'] == gene_id\n",
    "            ]\n",
    "            X1 = sub1.X.astype(float).toarray()\n",
    "            X2 = sub2.X.astype(float).toarray()\n",
    "            if X1.sum() == 0 or X2.sum() == 0:\n",
    "                filtered_with_valid_genes = filtered_with_valid_genes[:, filtered_with_valid_genes.var['geneId'] != gene_id]\n",
    "                continue\n",
    "            percent_1 = X1 / X1.sum()\n",
    "            percent_2 = X2 / X2.sum()\n",
    "            diff_found = False\n",
    "            for col_idx in range(percent_1.shape[1]):\n",
    "                if abs(percent_1[:, col_idx].sum() - percent_2[:, col_idx].sum()) > min_diff:\n",
    "                    diff_found = True\n",
    "                    break\n",
    "            if not diff_found:\n",
    "                filtered_with_valid_genes = filtered_with_valid_genes[:, filtered_with_valid_genes.var['geneId'] != gene_id]\n",
    "\n",
    "        return AnnDataIso(filtered_with_valid_genes, self.obs['cell_type'])\n",
    "\n",
    "    def __find_major_minor_isoforms(self):\n",
    "        df = self.__filtered_anndata.to_df()\n",
    "        df['cell_type'] = self.__filtered_anndata.obs['cell_type']\n",
    "        df = df.groupby('cell_type').mean().transpose()\n",
    "        df['geneId'] = self.__filtered_anndata.var['geneId']\n",
    "        df['is_major'] = ''\n",
    "        for ct in self.__filtered_anndata.obs['cell_type'].unique():\n",
    "            df.loc[df[ct] == df.groupby('geneId')[ct].transform('max'), 'is_major'] += ct + ','\n",
    "        di = df['is_major'].to_dict()\n",
    "        d = dict()\n",
    "        for (k, v) in di.items():\n",
    "            d[k] = len(v.split(',')) - 1\n",
    "        tr_ids = list(set(k for (k, v) in d.items() if v == 1))\n",
    "        return tr_ids\n",
    "\n",
    "    def find_major_minor_isoforms(self):\n",
    "        return self.__find_major_minor_isoforms()\n",
    "\n",
    "    ############################################################\n",
    "    # New: Wilcoxon-based approach for switching isoforms\n",
    "    ############################################################\n",
    "    def __scanpy_wilcoxon_switching_isoforms(self, cell_labels_column='cell_type',\n",
    "                                             min_fdr=0.05, min_log_fold_change=0.3):\n",
    "        \"\"\"\n",
    "        Mimics the 'get_isoswitches' function you provided, but uses 'self' as the AnnData object.\n",
    "        Returns a DataFrame of switching isoforms based on Scanpy's rank_genes_groups (Wilcoxon).\n",
    "        \"\"\"\n",
    "        import scanpy as sc\n",
    "\n",
    "        # We'll work on a copy to avoid mutating 'self'\n",
    "        adata = self.copy()\n",
    "\n",
    "        # If the anndata is empty, return empty DataFrame\n",
    "        if adata.shape[0] == 0:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # By default, ensure transcriptId is in var\n",
    "        if 'transcriptId' not in adata.var.columns:\n",
    "            adata.var['transcriptId'] = adata.var_names\n",
    "\n",
    "        # Make sure the label column is categorical\n",
    "        adata.obs[cell_labels_column] = adata.obs[cell_labels_column].astype('category')\n",
    "        groups = adata.obs[cell_labels_column].cat.categories\n",
    "\n",
    "        if len(groups) < 2:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        from itertools import combinations\n",
    "        group_contrasts = list(combinations(groups, 2))\n",
    "        marker_results_list = {}\n",
    "\n",
    "        # Perform Wilcoxon-based tests for each pair in both directions\n",
    "        for group_1, group_2 in group_contrasts:\n",
    "            try:\n",
    "                sc.tl.rank_genes_groups(\n",
    "                    adata, groupby=cell_labels_column, groups=[group_1],\n",
    "                    reference=group_2, method='wilcoxon', n_genes=adata.shape[0]\n",
    "                )\n",
    "                df1 = sc.get.rank_genes_groups_df(adata, group=group_1)\n",
    "                df1['group_1'] = group_1\n",
    "                df1['group_2'] = group_2\n",
    "                df1['contrast'] = f\"{group_1}__{group_2}\"\n",
    "\n",
    "                sc.tl.rank_genes_groups(\n",
    "                    adata, groupby=cell_labels_column, groups=[group_2],\n",
    "                    reference=group_1, method='wilcoxon', n_genes=adata.shape[0]\n",
    "                )\n",
    "                df2 = sc.get.rank_genes_groups_df(adata, group=group_2)\n",
    "                df2['group_1'] = group_2\n",
    "                df2['group_2'] = group_1\n",
    "                df2['contrast'] = f\"{group_1}__{group_2}\"\n",
    "\n",
    "                if not df1.empty and not df2.empty:\n",
    "                    marker_results_list[df1['contrast'].iloc[0]] = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "            except ValueError:\n",
    "                pass  # skip if it fails\n",
    "\n",
    "        if not marker_results_list:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        marker_df = pd.concat(marker_results_list.values(), ignore_index=True)\n",
    "\n",
    "        # If 'transcriptId' isn't in var, try resetting index\n",
    "        if 'transcriptId' not in adata.var.columns:\n",
    "            adata.var.reset_index(inplace=True)\n",
    "\n",
    "        # Map transcripts to genes\n",
    "        transcript_to_gene = adata.var.set_index('transcriptId')['geneId'].to_dict()\n",
    "        marker_df['geneId'] = marker_df['names'].map(transcript_to_gene)\n",
    "\n",
    "        # Add cell counts\n",
    "        cell_counts = adata.obs[cell_labels_column].value_counts()\n",
    "        marker_df['n_cells_group_1'] = marker_df['group_1'].map(cell_counts)\n",
    "        marker_df['n_cells_group_2'] = marker_df['group_2'].map(cell_counts)\n",
    "        marker_df['total_cells'] = marker_df['n_cells_group_1'] + marker_df['n_cells_group_2']\n",
    "\n",
    "        # Adjust p-values and filter\n",
    "        marker_df['adj_pval'] = multipletests(marker_df['pvals_adj'], method='fdr_bh')[1]\n",
    "        marker_df_filtered = marker_df[\n",
    "            (marker_df['adj_pval'] <= min_fdr) &\n",
    "            (marker_df['logfoldchanges'].abs() >= min_log_fold_change)\n",
    "        ]\n",
    "\n",
    "        def assign_direction(df):\n",
    "            return df.assign(\n",
    "                direction=np.where(\n",
    "                    df['group_1'] == df['contrast'].str.split(\"__\").str[0],\n",
    "                    df['logfoldchanges'],\n",
    "                    -df['logfoldchanges']\n",
    "                )\n",
    "            )\n",
    "\n",
    "        isoswitch_df = (\n",
    "            marker_df_filtered\n",
    "            .groupby(['geneId', 'contrast'])\n",
    "            .apply(assign_direction)\n",
    "            .reset_index(drop=True)\n",
    "            .groupby(['geneId', 'contrast'])\n",
    "            .filter(lambda x: (\n",
    "                len(x['group_1'].unique()) > 1 and\n",
    "                len(x['names'].unique()) > 1 and\n",
    "                x['direction'].abs().sum() != 0\n",
    "            ))\n",
    "        )\n",
    "\n",
    "        def calculate_percent_expression(adata, groupby_column, group, transcript):\n",
    "            subset = adata[adata.obs[groupby_column] == group, transcript]\n",
    "            return (subset.X > 0).mean() * 100\n",
    "\n",
    "        percent_expressions = isoswitch_df.apply(\n",
    "            lambda row: pd.Series({\n",
    "                'percent_expressed_group_1': calculate_percent_expression(adata, cell_labels_column, row['group_1'], row['names']),\n",
    "                'percent_expressed_group_2': calculate_percent_expression(adata, cell_labels_column, row['group_2'], row['names'])\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "        isoswitch_df = pd.concat([isoswitch_df, percent_expressions], axis=1)\n",
    "        isoswitch_df.sort_values(by='adj_pval', inplace=True)\n",
    "\n",
    "        return isoswitch_df\n",
    "\n",
    "    ################################################################\n",
    "    # Updated find_switching_isoforms(...) with method switch\n",
    "    ################################################################\n",
    "    def find_switching_isoforms(\n",
    "        self,\n",
    "        cell_group_column='cell_type',\n",
    "        min_count=30,\n",
    "        min_diff=0.2,\n",
    "        method=\"ScanpyWilcoxon\",\n",
    "        min_fdr=0.05,\n",
    "        min_log_fold_change=0.5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Finds switching isoforms. By default uses the Wilcoxon-based method\n",
    "        (Scanpy's rank_genes_groups). If you want the original Dirichlet-based\n",
    "        approach, call with method='Dirichlet'.\n",
    "\n",
    "        For method='Dirichlet', 'min_count' and 'min_diff' apply.\n",
    "        For method='ScanpyWilcoxon', 'min_fdr' and 'min_log_fold_change' apply.\n",
    "        \"\"\"\n",
    "        if method == \"Dirichlet\":\n",
    "            # Original approach\n",
    "            cell_types = self.obs[cell_group_column].unique()\n",
    "            gene_ids = self.var['geneId'].unique()\n",
    "\n",
    "            def process_gene(obj, group_1_label, group_2_label, gene_id):\n",
    "                result = obj.__compare_groups(group_1_label, group_2_label, cell_group_column, gene_id)\n",
    "                if result:\n",
    "                    return {\n",
    "                        'gene_id': gene_id,\n",
    "                        'group_1': group_1_label,\n",
    "                        'group_2': group_2_label,\n",
    "                        'p_value': result['p_value'],\n",
    "                        'chi2_stat': result['chi2_stat'],\n",
    "                        'alpha_combined': result['alpha_combined'],\n",
    "                        'alpha1': result['alpha1'],\n",
    "                        'alpha2': result['alpha2'],\n",
    "                        'transcript_ids': result['transcript_ids']\n",
    "                    }\n",
    "                return None\n",
    "\n",
    "            results = []\n",
    "            for group_1_label, group_2_label in combinations(cell_types, 2):\n",
    "                filtered_adata = self.__filter_genes(group_1_label, group_2_label, cell_group_column, min_count, min_diff)\n",
    "                pairwise_results = []\n",
    "                for gene_id in gene_ids:\n",
    "                    if gene_id not in filtered_adata.var['geneId'].values:\n",
    "                        continue\n",
    "                    res = process_gene(filtered_adata, group_1_label, group_2_label, gene_id)\n",
    "                    if res is not None:\n",
    "                        pairwise_results.append(res)\n",
    "                results.extend(pairwise_results)\n",
    "\n",
    "            results_df = pd.DataFrame(results)\n",
    "            self.relevant_genes = results_df\n",
    "            return results_df\n",
    "        else:\n",
    "            # New default approach: Wilcoxon-based\n",
    "            isoswitch_df = self.__scanpy_wilcoxon_switching_isoforms(\n",
    "                cell_labels_column=cell_group_column,\n",
    "                min_fdr=min_fdr,\n",
    "                min_log_fold_change=min_log_fold_change\n",
    "            )\n",
    "            return isoswitch_df\n",
    "\n",
    "    def plot_relevant_genes(self, gene_id, p_value_threashold=0.05, data=None):\n",
    "        if data is not None:\n",
    "            self.relevant_genes = data\n",
    "        if not hasattr(self, 'relevant_genes') or self.relevant_genes is None:\n",
    "            raise Exception('Please run the `%s` method on this object in order to preprocess the needed data.' % ('find_switching_isoforms'))\n",
    "        switching_genes = self.relevant_genes[\n",
    "            (self.relevant_genes['gene_id'] == gene_id)\n",
    "            & (self.relevant_genes['p_value'] < p_value_threashold)\n",
    "        ]\n",
    "        switching_genes[['cell_type']] = self.obs[['cell_type']]\n",
    "        column_names = self.to_df().columns.tolist()\n",
    "        transcr_indexes = list(map(str, column_names))\n",
    "\n",
    "        cell_types_compare = switching_genes[\n",
    "            (self.relevant_genes['gene_id'] == gene_id)\n",
    "            & (switching_genes['p_value'] < p_value_threashold)\n",
    "        ][['group_1', 'group_2']].values.tolist()\n",
    "        cell_types_compare = list(set([x for xs in cell_types_compare for x in xs]))\n",
    "        tr_ids = switching_genes[\n",
    "            (self.relevant_genes['gene_id'] == gene_id)\n",
    "            & (switching_genes['p_value'] < p_value_threashold)\n",
    "        ]['transcript_ids'].values.tolist()\n",
    "        tr_ids_json = [tr_id for tr_id in tr_ids]\n",
    "        tr_ids_flattened = list(set([x for xs in tr_ids_json for x in xs]))\n",
    "        fig = plt.figure()\n",
    "\n",
    "        data = self.to_df()\n",
    "        data[['cell_type']] = self.obs[['cell_type']]\n",
    "        genes_sum = data[data['cell_type'].isin(cell_types_compare)][tr_ids_flattened + ['cell_type']].groupby('cell_type').sum()\n",
    "        genes_nonzero = data[data['cell_type'].isin(cell_types_compare)].groupby('cell_type').apply(lambda x: (x != 0).sum())[tr_ids_flattened]\n",
    "\n",
    "        color_data = genes_nonzero[tr_ids_flattened].to_numpy()\n",
    "        size_data = genes_sum[tr_ids_flattened].to_numpy()\n",
    "        x_labels = tr_ids_flattened\n",
    "\n",
    "        # 'scattermap' presumably from your code\n",
    "        ax = scattermap(\n",
    "            color_data, marker_size=size_data, square=True, cmap=\"Reds\",\n",
    "            cbar_kws={\"label\": \"Non-zeros\"},\n",
    "            xticklabels=x_labels, yticklabels=cell_types_compare\n",
    "        )\n",
    "        mk_size = 60\n",
    "        ax.scatter(-1, -1, label=f\"{np.amax(size_data):0.1f}\", marker=\"o\", c=\"r\", s=mk_size)\n",
    "        ax.scatter(-1, -1, label=f\"{np.mean(size_data):0.1f}\", marker=\"o\", c=\"r\", s=mk_size * 0.5)\n",
    "        if np.any(size_data > 0):\n",
    "            nz_min = np.amin(size_data[np.nonzero(size_data)])\n",
    "        else:\n",
    "            nz_min = 0.0\n",
    "        ax.scatter(-1, -1, label=f\"{nz_min:0.1f}\", marker=\"o\", c=\"r\", s=mk_size * 0.1)\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1.27, -0.05))\n",
    "        fig.tight_layout()\n",
    "\n",
    "    def plot_relevant_genes(self, gene_id, p_value_threashold=0.05, data=None):\n",
    "        if data is not None:\n",
    "            self.relevant_genes = data\n",
    "        if not hasattr(self, 'relevant_genes') or self.relevant_genes is None:\n",
    "            raise Exception('Please run the `%s` method on this object in order to preprocess the needed data.' % ('find_switching_isoforms'))\n",
    "        switching_genes = self.relevant_genes[\n",
    "            (self.relevant_genes['gene_id'] == gene_id)\n",
    "            & (self.relevant_genes['p_value'] < p_value_threashold)\n",
    "        ]\n",
    "        switching_genes[['cell_type']] = self.obs[['cell_type']]\n",
    "        column_names = self.to_df().columns.tolist()\n",
    "        transcr_indexes = list(map(str, column_names))\n",
    "\n",
    "        cell_types_compare = switching_genes[\n",
    "            (self.relevant_genes['gene_id'] == gene_id)\n",
    "            & (switching_genes['p_value'] < p_value_threashold)\n",
    "        ][['group_1', 'group_2']].values.tolist()\n",
    "        cell_types_compare = list(set([x for xs in cell_types_compare for x in xs]))\n",
    "        tr_ids = switching_genes[\n",
    "            (self.relevant_genes['gene_id'] == gene_id)\n",
    "            & (switching_genes['p_value'] < p_value_threashold)\n",
    "        ]['transcript_ids'].values.tolist()\n",
    "        tr_ids_json = [tr_id for tr_id in tr_ids]\n",
    "        tr_ids_flattened = list(set([x for xs in tr_ids_json for x in xs]))\n",
    "        fig = plt.figure()\n",
    "\n",
    "        data = self.to_df()\n",
    "        data[['cell_type']] = self.obs[['cell_type']]\n",
    "        genes_sum = data[data['cell_type'].isin(cell_types_compare)][tr_ids_flattened + ['cell_type']].groupby('cell_type').sum()\n",
    "        genes_nonzero = data[data['cell_type'].isin(cell_types_compare)].groupby('cell_type').apply(lambda x: (x != 0).sum())[tr_ids_flattened]\n",
    "\n",
    "        # 'scattermap' is presumably from your code\n",
    "        color_data = genes_nonzero[tr_ids_flattened].to_numpy()\n",
    "        size_data = genes_sum[tr_ids_flattened].to_numpy()\n",
    "        x_labels = tr_ids_flattened\n",
    "        ax = scattermap(\n",
    "            color_data, marker_size=size_data, square=True, cmap=\"Reds\",\n",
    "            cbar_kws={\"label\": \"Non-zeros\"},\n",
    "            xticklabels=x_labels, yticklabels=cell_types_compare\n",
    "        )\n",
    "        mk_size = 60\n",
    "        ax.scatter(-1, -1, label=f\"{np.amax(size_data):0.1f}\", marker=\"o\", c=\"r\", s=mk_size)\n",
    "        ax.scatter(-1, -1, label=f\"{np.mean(size_data):0.1f}\", marker=\"o\", c=\"r\", s=mk_size * 0.5)\n",
    "        if np.any(size_data > 0):\n",
    "            nz_min = np.amin(size_data[np.nonzero(size_data)])\n",
    "        else:\n",
    "            nz_min = 0.0\n",
    "        ax.scatter(-1, -1, label=f\"{nz_min:0.1f}\", marker=\"o\", c=\"r\", s=mk_size * 0.1)\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1.27, -0.05))\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489add128907b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_iso_adata(\n",
    "    path: str  # Path to a tab-separated file, typically the Sicelore output with transcript counts.\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an AnnData object containing isoform counts from a Sicelore output file.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): Path to the input file, which is expected to be tab-separated and contain:\n",
    "        - `transcriptId`: Transcript identifiers.\n",
    "        - `geneId`: Gene identifiers.\n",
    "        - Transcript counts for individual barcodes (cells) as additional columns.\n",
    "\n",
    "    Returns:\n",
    "    - adata_iso (AnnData): An AnnData object with isoform counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input file and read it into a Pandas DataFrame\n",
    "    with open(path) as isoforms:\n",
    "        df = pd.read_table(isoforms, sep='\\t')\n",
    "\n",
    "    # Extract the count matrix\n",
    "    # - `df.iloc[0:, 2:]`: assuming these are counts.\n",
    "    counts = df.iloc[0:, 2:]\n",
    "\n",
    "    # Create an AnnData object with the count matrix\n",
    "\n",
    "    adata_iso = ad.AnnData(counts).transpose()\n",
    "\n",
    "    # Assign transcript IDs as variable names (columns in the original file)\n",
    "    adata_iso.var_names = df['transcriptId'].to_list()\n",
    "\n",
    "    # Add additional variable-level metadata\n",
    "    # - Include both `transcriptId` and `geneId` as annotations for the variables.\n",
    "    adata_iso.var = df[['transcriptId', 'geneId']]\n",
    "\n",
    "    # Create observation-level metadata for barcodes (cells)\n",
    "    # - Extract column names (barcodes) starting from the 3rd column (index 2).\n",
    "    barcodes = {'barcodes': df.columns.values[2:]}\n",
    "    barcodes = pd.DataFrame(data=barcodes)\n",
    "\n",
    "    # Assign the barcodes DataFrame to the AnnData object as observation metadata\n",
    "    adata_iso.obs = barcodes\n",
    "\n",
    "    # Set observation names (row indices) in the AnnData object to match the barcodes\n",
    "    adata_iso.obs_names = barcodes['barcodes'].tolist()\n",
    "\n",
    "    # Return the AnnData object containing isoform counts\n",
    "    return adata_iso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
