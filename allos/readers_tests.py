# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/003_readers_tests.ipynb.

# %% auto 0
__all__ = ['download_test_data', 'iso_concat', 'read_sicelore_isomatrix']

# %% ../nbs/003_readers_tests.ipynb 2
import urllib
import urllib.request
import gzip
import shutil

# %% ../nbs/003_readers_tests.ipynb 4
def download_test_data(url: str = "https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3748nnn/GSM3748087/suppl/GSM3748087%5F190c.isoforms.matrix.txt.gz") -> str:
    """
    Downloads a test data file from a specified URL, saves it locally, and extracts it.

    Parameters:
    url (str): The URL of the file to be downloaded. Defaults to a pre-defined test dataset.

    Returns:
    str: The absolute path of the extracted file if the download is successful, or None if it fails.
    """
    print(f"Starting download of test data from {url}")

    # Extract filename from the URL
    filename = url.split('/')[-1]
    compressed_file = filename

    # Generate a unique filename for the extracted file
    base_extracted_file = "sample_isomatrix"
    counter = 1
    extracted_file = f"{base_extracted_file}.txt"
    while os.path.exists(extracted_file):
        extracted_file = f"{base_extracted_file}_{counter}.txt"
        counter += 1

    # Download the file from the given URL
    try:
        urllib.request.urlretrieve(url, compressed_file)
        print("File downloaded successfully")
    except Exception as e:
        print(f"Failed to download the file: {e}")
        return None

    # Extract the file
    try:
        with gzip.open(compressed_file, 'rb') as f_in:
            with open(extracted_file, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)
        print("File extracted successfully")
        return os.path.abspath(extracted_file)
    except Exception as e:
        print(f"Failed to extract the file: {e}")
        return None
    finally:
        # Clean up the compressed file
        if os.path.exists(compressed_file):
            os.remove(compressed_file)




# %% ../nbs/003_readers_tests.ipynb 5
import os
import pandas as pd
import scanpy as sc
from anndata import AnnData

def iso_concat(data_inputs, batch_info=None, batch_type='path'):
    """
    Concatenates a list of AnnData objects or paths to AnnData objects based on the union of transcriptIds,
    while preserving geneId information which might be non-unique per transcriptId.
    Missing values are filled with zeros. Adds a batch column to `.obs` based on the file path, obs_names, or numeric.

    Parameters:
    data_inputs (list of str or AnnData):
        List of paths to AnnData objects or AnnData objects to concatenate.
    batch_info (list of str, optional):
        List of batch identifiers for each AnnData object in data_inputs.
        If not provided, batch identifiers are extracted from file paths, obs_names, or a numeric sequence.
    batch_type (str, optional):
        Specifies which type of batch information to use. One of ['path', 'obs_names', 'numeric'].
        Defaults to 'path'.

    Returns:
    AnnData:
        A single concatenated AnnData object with harmonized features, geneId annotations, and batch info.
    """
    adata_list = []
    df_list = []
    gene_ids = {}
    batch_info_list = []

    for i, data_input in enumerate(data_inputs):
        # Check if the input is a path (string) or an AnnData object
        if isinstance(data_input, str):
            adata = sc.read_h5ad(data_input)
            # Determine batch label based on batch_type
            if batch_type == 'path':
                batch = os.path.basename(data_input).split('_isomatrix')[0] if batch_info is None else batch_info[i]
            elif batch_type == 'obs_names':
                batch = adata.obs_names[0] if batch_info is None else batch_info[i]
            elif batch_type == 'numeric':
                batch = str(i)
            else:
                raise ValueError("batch_type should be 'path', 'obs_names' or 'numeric'.")
        elif isinstance(data_input, AnnData):
            adata = data_input
            # Determine batch label when input is already an AnnData object
            if batch_type == 'obs_names':
                batch = adata.obs_names[0] if batch_info is None else batch_info[i]
            elif batch_type == 'numeric':
                batch = str(i)
            else:
                raise ValueError("batch_type should be 'obs_names' or 'numeric' when passing AnnData objects.")
        else:
            raise ValueError("data_inputs must be a list of paths to AnnData objects or AnnData objects.")

        adata_list.append(adata)
        # Convert adata.X to a DataFrame for outer-join concatenation
        df = pd.DataFrame(adata.X.T, index=adata.var['transcriptId'], columns=adata.obs_names)
        df_list.append(df)
        batch_info_list.extend([batch] * adata.n_obs)

        # Map transcriptId to its geneId
        for transcript_id, gene_id in zip(adata.var['transcriptId'], adata.var['geneId']):
            gene_ids[transcript_id] = gene_id

    # Perform an outer join on all DataFrames
    concat_df = pd.concat(df_list, axis=1, join='outer').fillna(0)

    # Create a new var DataFrame with geneIds mapped from transcriptIds
    var_df = pd.DataFrame(index=concat_df.index)
    var_df['geneId'] = pd.Series(gene_ids).reindex(concat_df.index)

    # Build an AnnData object, transposing so obs are rows
    concatenated_adata = sc.AnnData(X=concat_df.T, var=var_df)

    # Add batch info to obs
    concatenated_adata.obs['batch'] = batch_info_list

    return concatenated_adata



# %% ../nbs/003_readers_tests.ipynb 6
import pandas as pd
import warnings
from scipy.sparse import csr_matrix
import scanpy as sc
from anndata import AnnData

def read_sicelore_isomatrix(
    file_path: str,
    gene_id_label: str = "geneId",
    transcript_id_label: str = "transcriptId",
    remove_undef: bool = True,
    sparse: bool = False
) -> AnnData:
    """
    Read a SiCeLoRe isomatrix file (tab-delimited) and convert it into a scanpy-compatible AnnData object.

    Parameters
    ----------
    file_path : str
        Path to the isomatrix file (tab-delimited).
    gene_id_label : str, optional
        Row/column label used for gene IDs (default "geneId").
    transcript_id_label : str, optional
        Row/column label used for transcript IDs (default "transcriptId").
    remove_undef : bool, optional
        Whether to remove rows with transcriptId="undef" (default True).
    sparse : bool, optional
        Whether to store the matrix in sparse format (default False).

    Returns
    -------
    anndata.AnnData
        An AnnData object containing numeric data in `.X` and metadata in `.var`.
    """
    # Read in the file, expecting rows to be features initially
    df = pd.read_csv(file_path, sep='\t', index_col=0)

    # Optionally remove rows marked as "undef" in the transcript column
    if remove_undef and (transcript_id_label in df.columns):
        df = df[df[transcript_id_label] != "undef"]

    # Reset and transpose so columns become features (var) and rows become observations (obs)
    df = df.reset_index()
    df = df.transpose()

    # Identify potential metadata rows (e.g., geneId, transcriptId, nbExons)
    known_metadata_labels = [gene_id_label, transcript_id_label]
    metadata_rows = [idx for idx in df.index if idx in known_metadata_labels or "Exons" in idx]

    # Extract metadata if present
    metadata_df = df.loc[metadata_rows] if metadata_rows else pd.DataFrame()
    # Drop them from the numeric data
    df = df.drop(metadata_rows, errors='ignore')

    # Convert to float and optionally to a sparse matrix
    try:
        numeric_data = df.values.astype('float32')
    except ValueError:
        print("Error: Non-numeric data present in the DataFrame. Cannot convert to float.")
        return None

    if sparse:
        numeric_data = csr_matrix(numeric_data)

    # Create AnnData object
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        adata = sc.AnnData(
            X=numeric_data,
            obs=pd.DataFrame(index=df.index.astype(str)),
            var=pd.DataFrame(index=df.columns.astype(str))
        )

    # Attach metadata to the AnnData var
    if not metadata_df.empty:
        for row_label in metadata_df.index.unique():
            adata.var[row_label] = metadata_df.loc[row_label].astype(str).values

    # Make observation names unique
    adata.obs_names_make_unique()

    return adata

